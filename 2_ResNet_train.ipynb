{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","toc_visible":true,"mount_file_id":"14fUFS_IT3-IWAgnBkKyDJMt0sQX4dj-i","authorship_tag":"ABX9TyOQTum+YHXdSi9ecAtgB4Vv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## 00 Install"],"metadata":{"id":"wfjalG9B24DQ"}},{"cell_type":"code","source":["# !pip install torchinfo\n","# !pip install modules\n","# !pip install pymysql sqlalchemy"],"metadata":{"id":"0RSLLBJc22tE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 01 Import"],"metadata":{"id":"acjiRtJN7oJ6"}},{"cell_type":"code","source":["# import libraries\n","import os\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import os.path\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import time\n","\n","import torch\n","import torchvision\n","from torchvision import models\n","from torch import nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import ImageFolder\n","from torchinfo import summary\n","import torchvision.transforms as transforms\n","\n","from pathlib import Path\n","from typing import Tuple, List, Dict, Optional\n","import random\n","from PIL import Image, ImageDraw\n","from torchvision.utils import make_grid\n","\n","# ë””ë°”ì´ìŠ¤ ì„¤ì •\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"sedXL5wU28a8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 02 Load Dataset"],"metadata":{"id":"HaUAiihp8Xii"}},{"cell_type":"code","source":["# ë°ì´í„° ê²½ë¡œ ì„¤ì •\n","data_dir = 'your_path/fruit-and-vegetable-image'\n","\n","# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n","train_dir = os.path.join(data_dir, 'train')\n","train_filepaths = list(Path(train_dir).rglob('*.jpg')) + \\\n","                  list(Path(train_dir).rglob('*.jpeg')) + \\\n","                  list(Path(train_dir).rglob('*.png')) + \\\n","                  list(Path(train_dir).rglob('*.JPG'))\n","\n","test_dir = os.path.join(data_dir, 'test')\n","test_filepaths = list(Path(test_dir).rglob('*.jpg')) + \\\n","                 list(Path(test_dir).rglob('*.jpeg')) + \\\n","                 list(Path(test_dir).rglob('*.png')) + \\\n","                 list(Path(test_dir).rglob('*.JPG'))\n","\n","val_dir = os.path.join(data_dir, 'validation')\n","val_filepaths = list(Path(val_dir).rglob('*.jpg')) + \\\n","                 list(Path(val_dir).rglob('*.jpeg')) + \\\n","                 list(Path(val_dir).rglob('*.png')) + \\\n","                 list(Path(val_dir).rglob('*.JPG'))\n","\n","\n","def proc_img(filepath):\n","    \"\"\"\n","    ì´ë¯¸ì§€ íŒŒì¼ì˜ ê²½ë¡œì™€ ë¼ë²¨ì„ í¬í•¨í•˜ëŠ” DataFrameì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\n","    \"\"\"\n","\n","    # íŒŒì¼ ê²½ë¡œì—ì„œ ë¼ë²¨(í´ë”ëª…) ì¶”ì¶œ\n","    labels = [str(filepath[i]).split(\"/\")[-2] for i in range(len(filepath))]\n","\n","    # íŒŒì¼ ê²½ë¡œë¥¼ pandas Seriesë¡œ ë³€í™˜í•˜ê³  ë¬¸ìì—´ë¡œ ì €ì¥\n","    filepath = pd.Series(filepath, name='Filepath').astype(str)\n","\n","    # ë¼ë²¨ì„ pandas Seriesë¡œ ë³€í™˜\n","    labels = pd.Series(labels, name='Label')\n","\n","    # íŒŒì¼ ê²½ë¡œì™€ ë¼ë²¨ì„ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ í•©ì¹˜ê¸°\n","    df = pd.concat([filepath, labels], axis=1)\n","\n","    # ë°ì´í„° í”„ë ˆì„ì„ ëœë¤í•˜ê²Œ ì„ê³  ì¸ë±ìŠ¤ ì´ˆê¸°í™”\n","    df = df.sample(frac=1).reset_index(drop=True)\n","\n","    return df\n","\n","# í•™ìŠµ(train), í…ŒìŠ¤íŠ¸(test), ê²€ì¦(validation) ë°ì´í„° í”„ë ˆì„ ìƒì„±\n","train_df = proc_img(train_filepaths)\n","test_df = proc_img(test_filepaths)\n","val_df = proc_img(val_filepaths)\n","\n","# í´ë˜ìŠ¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n","class_labels = train_df.Label.unique()"],"metadata":{"id":"ZoWC8bz0lUpH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 03 Create Transformer"],"metadata":{"id":"KWap5H_13nm1"}},{"cell_type":"code","source":["# ResNet-18 ëª¨ë¸ì˜ ê¸°ë³¸ ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜(Weights) ë¶ˆëŸ¬ì˜¤ê¸°\n","ResNet_weights = models.ResNet50_Weights.DEFAULT\n","\n","# í•´ë‹¹ ê°€ì¤‘ì¹˜ì— ë§ëŠ” ë³€í™˜(transform) ê°ì²´ ê°€ì ¸ì˜¤ê¸°\n","ResNet_transformer = ResNet_weights.transforms()  # ëª¨ë¸ì´ ìš”êµ¬í•˜ëŠ” ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì´ ë°˜í™˜\n","\n","# ë³€í™˜ ê°ì²´ ì¶œë ¥ (ì–´ë–¤ ë³€í™˜ì´ ì ìš©ë˜ëŠ”ì§€ í™•ì¸)\n","ResNet_transformer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"024RhS9w2csY","executionInfo":{"status":"ok","timestamp":1743311042142,"user_tz":-540,"elapsed":5,"user":{"displayName":"ì´ìˆ˜ì¸","userId":"16249151905029041959"}},"outputId":"8f383431-505e-4ef1-f6e7-0b4f1c3e1221"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ImageClassification(\n","    crop_size=[224]\n","    resize_size=[232]\n","    mean=[0.485, 0.456, 0.406]\n","    std=[0.229, 0.224, 0.225]\n","    interpolation=InterpolationMode.BILINEAR\n",")"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# ëœë¤í•œ ì‚¬ê°í˜• ë…¸ì´ì¦ˆ ì¶”ê°€ í•¨ìˆ˜\n","def add_rectangle_noise(image):\n","    \"\"\"ì´ë¯¸ì§€ì— ëœë¤í•œ í¬ê¸°ì™€ ìœ„ì¹˜ì˜ ì‚¬ê°í˜• ë…¸ì´ì¦ˆ ì¶”ê°€\"\"\"\n","    draw = ImageDraw.Draw(image)\n","    width, height = image.size\n","\n","    # ë…¸ì´ì¦ˆ í¬ê¸° (ì „ì²´ ì´ë¯¸ì§€ í¬ê¸°ì˜ 30~50%)\n","    box_width = random.randint(int(0.3 * width), int(0.5 * width))\n","    box_height = random.randint(int(0.3 * height), int(0.5 * height))\n","\n","    # ëœë¤ ìœ„ì¹˜\n","    x1 = random.randint(0, width - box_width)\n","    y1 = random.randint(0, height - box_height)\n","    x2 = x1 + box_width\n","    y2 = y1 + box_height\n","\n","    # ëœë¤ ìƒ‰ìƒ (0~255 ë²”ìœ„)\n","    noise_color = tuple(np.random.randint(0, 256, size=3).tolist())\n","\n","    # ì‚¬ê°í˜• ê·¸ë¦¬ê¸°\n","    draw.rectangle([x1, y1, x2, y2], fill=noise_color)\n","    return image\n","\n","# ë°ì´í„°ì…‹ ì¦ê°• ë° ë³€í™˜ ì ìš©\n","augmented_transform = transforms.Compose([\n","    transforms.RandomRotation(20),  # -20ë„ ~ 20ë„ íšŒì „\n","    transforms.RandomHorizontalFlip(),  # 50% í™•ë¥ ë¡œ ì¢Œìš° ë°˜ì „\n","    transforms.Lambda(lambda img: add_rectangle_noise(img)),  # ëœë¤í•œ ì‚¬ê°í˜• ë…¸ì´ì¦ˆ ì¶”ê°€\n","    ResNet_transformer  # MobileNetV3 ê¸°ë³¸ ë³€í™˜ ì ìš©\n","])\n","\n","# ì›ë³¸ê³¼ ì¦ê°• ë°ì´í„°ì…‹ì„ ê°ê° ìƒì„±\n","train_data_original = ImageFolder(root=train_dir, transform=ResNet_transformer)  # ì›ë³¸ ë°ì´í„°\n","train_data_augmented = ImageFolder(root=train_dir, transform=augmented_transform)  # ì¦ê°• ë°ì´í„°\n","\n","validation_data_original = ImageFolder(root=val_dir, transform=ResNet_transformer)  # ê²€ì¦ ì›ë³¸ ë°ì´í„°\n","validation_data_augmented = ImageFolder(root=val_dir, transform=augmented_transform)  # ê²€ì¦ ì¦ê°• ë°ì´í„°\n","\n","# ê²°í•©\n","train_data_transformed = torch.utils.data.ConcatDataset([train_data_original, train_data_augmented])\n","validation_data_transformed = torch.utils.data.ConcatDataset([validation_data_original, validation_data_augmented])\n","\n","print(f\"Original dataset size: {len(train_data_original)}\")\n","print(f\"Augmented dataset size: {len(train_data_augmented)}\")\n","print(f\"Combined dataset size: {len(train_data_transformed)}\")\n","print(f\"Validation dataset szie: {len(validation_data_transformed)}\")\n","\n","# í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ ìœ ì§€\n","test_data_transformed = ImageFolder(root=test_dir, transform=ResNet_transformer)\n","\n","# ë³€í™˜ëœ ë°ì´í„°ì…‹ í™•ì¸\n","print(train_data_original, '\\n\\n', train_data_augmented)"],"metadata":{"id":"XBf_Bwysucgu","executionInfo":{"status":"ok","timestamp":1743311042240,"user_tz":-540,"elapsed":97,"user":{"displayName":"ì´ìˆ˜ì¸","userId":"16249151905029041959"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"071f6512-d77a-4430-9ee0-e9730c76a55e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original dataset size: 3115\n","Augmented dataset size: 3115\n","Combined dataset size: 6230\n","Validation dataset szie: 702\n","Dataset ImageFolder\n","    Number of datapoints: 3115\n","    Root location: /content/drive/MyDrive/Colab_Notebooks/fruit-and-vegetable-image/train\n","    StandardTransform\n","Transform: ImageClassification(\n","               crop_size=[224]\n","               resize_size=[232]\n","               mean=[0.485, 0.456, 0.406]\n","               std=[0.229, 0.224, 0.225]\n","               interpolation=InterpolationMode.BILINEAR\n","           ) \n","\n"," Dataset ImageFolder\n","    Number of datapoints: 3115\n","    Root location: /content/drive/MyDrive/Colab_Notebooks/fruit-and-vegetable-image/train\n","    StandardTransform\n","Transform: Compose(\n","               RandomRotation(degrees=[-20.0, 20.0], interpolation=nearest, expand=False, fill=0)\n","               RandomHorizontalFlip(p=0.5)\n","               Lambda()\n","               ImageClassification(\n","               crop_size=[224]\n","               resize_size=[232]\n","               mean=[0.485, 0.456, 0.406]\n","               std=[0.229, 0.224, 0.225]\n","               interpolation=InterpolationMode.BILINEAR\n","           )\n","           )\n"]}]},{"cell_type":"markdown","source":["## 04 Dataloader"],"metadata":{"id":"PBJ1sO5a9oTk"}},{"cell_type":"code","source":["# ë°°ì¹˜ í¬ê¸° ë° ì›Œì»¤(worker) ìˆ˜ ì„¤ì •\n","BATCH_SIZE = 32  # í•œ ë²ˆì— í•™ìŠµí•  ë°ì´í„° ìƒ˜í”Œ ìˆ˜\n","NUM_WORKERS = os.cpu_count()  # ì‚¬ìš©í•  CPU ì½”ì–´ ê°œìˆ˜ (ìµœëŒ€ ì„±ëŠ¥ í™œìš©)\n","\n","# í•™ìŠµ ë°ì´í„° ë¡œë” ìƒì„±\n","train_dataloader = DataLoader(dataset=train_data_transformed,  # í•™ìŠµ ë°ì´í„°ì…‹\n","                              batch_size=BATCH_SIZE,  # ë°°ì¹˜ í¬ê¸° ì„¤ì •\n","                              num_workers=NUM_WORKERS,  # CPU ì›Œì»¤ ê°œìˆ˜ ì„¤ì •\n","                              shuffle=True,  # í•™ìŠµ ë°ì´í„°ëŠ” ëœë¤ìœ¼ë¡œ ì„ì–´ì„œ ë¡œë“œ\n","                              pin_memory=True)  # CUDA ì‚¬ìš© ì‹œ ë©”ëª¨ë¦¬ í•€ ì„¤ì • (ì†ë„ í–¥ìƒ)\n","\n","# ê²€ì¦ ë°ì´í„° ë¡œë” ìƒì„±\n","validation_dataloader = DataLoader(dataset=validation_data_transformed,\n","                                   batch_size=BATCH_SIZE,\n","                                   num_workers=NUM_WORKERS,\n","                                   shuffle=False,\n","                                   pin_memory=True)\n","\n","# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„±\n","test_dataloader = DataLoader(dataset=test_data_transformed,\n","                             batch_size=BATCH_SIZE,\n","                             num_workers=NUM_WORKERS,\n","                             shuffle=False,\n","                             pin_memory=True)"],"metadata":{"id":"5ZKAfXg840X0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 05 Modeling"],"metadata":{"id":"8LU-w3xJ7AcW"}},{"cell_type":"code","source":["# ResNet-50 ëª¨ë¸ ìƒì„± ë° ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì ìš©\n","ResNet_model = models.resnet50(weights=ResNet_weights).to(device)\n","\n","# íŠ¹ì§• ì¶”ì¶œê¸°(Feature Extractor) ë¶€ë¶„ ë™ê²°\n","for param in ResNet_model.parameters():\n","    param.requires_grad = False  # ê¸°ì¡´ ê°€ì¤‘ì¹˜ë¥¼ ê³ ì •í•˜ì—¬ í•™ìŠµë˜ì§€ ì•Šë„ë¡ ì„¤ì •\n","\n","# ëœë¤ ì‹œë“œ ê³ ì •\n","torch.manual_seed(42) # ë™ì¼í•œ ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•´ ëœë¤ ì‹œë“œ ì„¤ì • (CPU)\n","torch.cuda.manual_seed(42) # ë™ì¼í•œ ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•´ ëœë¤ ì‹œë“œ ì„¤ì • (GPU)\n","\n","# í´ë˜ìŠ¤ ìˆ˜ ì •ì˜ (ì´ë¯¸ ì •ì˜ëœ class_labels ì‚¬ìš©)\n","num_classes = len(class_labels)\n","\n","num_ftrs = ResNet_model.fc.in_features  # ê¸°ë³¸ì ìœ¼ë¡œ ResNet-50ì˜ fcëŠ” 2048 ì…ë ¥\n","\n","# ë¶„ë¥˜ê¸°(Classifier) ë ˆì´ì–´ ì¬êµ¬ì„±\n","ResNet_model.fc = nn.Sequential(\n","    nn.Dropout(p=0.2, inplace=True), # ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ë“œë¡­ì•„ì›ƒ ì¶”ê°€ (20% í™•ë¥ ë¡œ ë‰´ëŸ° ë¹„í™œì„±í™”))\n","    nn.Linear(in_features=num_ftrs, out_features=len(class_labels)) # ì¶œë ¥ ë‰´ëŸ° ìˆ˜ë¥¼ í´ë˜ìŠ¤ ê°œìˆ˜(len(class_labels))ë¡œ ì„¤ì •\n",")\n","\n","# ëª¨ë¸ ë””ë°”ì´ìŠ¤ ì´ë™\n","ResNet_model = ResNet_model.to(device)\n","\n","# ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ì—¬ ë³€ê²½ëœ ë¶€ë¶„ì„ í™•ì¸\n","summary(model=ResNet_model,  # ëª¨ë¸ ì§€ì •\n","        input_size=[32, 3, 224, 224],  # ì…ë ¥ ë°ì´í„° í¬ê¸° (batch_size=32, ì±„ë„=3, ë†’ì´=224, ë„ˆë¹„=224)\n","        col_names=['input_size', 'output_size', 'num_params', 'trainable'],  # ì¶œë ¥í•  ì •ë³´ ì„¤ì •\n","        row_settings=['var_names'])  # ë³€ìˆ˜ëª… ì¶œë ¥"],"metadata":{"id":"-R9ilfFx7qQY","executionInfo":{"status":"ok","timestamp":1743311044759,"user_tz":-540,"elapsed":2513,"user":{"displayName":"ì´ìˆ˜ì¸","userId":"16249151905029041959"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a8baf266-e41b-4220-aa5c-139e194a9b0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 174MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["============================================================================================================================================\n","Layer (type (var_name))                  Input Shape               Output Shape              Param #                   Trainable\n","============================================================================================================================================\n","ResNet (ResNet)                          [32, 3, 224, 224]         [32, 36]                  --                        Partial\n","â”œâ”€Conv2d (conv1)                         [32, 3, 224, 224]         [32, 64, 112, 112]        (9,408)                   False\n","â”œâ”€BatchNorm2d (bn1)                      [32, 64, 112, 112]        [32, 64, 112, 112]        (128)                     False\n","â”œâ”€ReLU (relu)                            [32, 64, 112, 112]        [32, 64, 112, 112]        --                        --\n","â”œâ”€MaxPool2d (maxpool)                    [32, 64, 112, 112]        [32, 64, 56, 56]          --                        --\n","â”œâ”€Sequential (layer1)                    [32, 64, 56, 56]          [32, 256, 56, 56]         --                        False\n","â”‚    â””â”€Bottleneck (0)                    [32, 64, 56, 56]          [32, 256, 56, 56]         --                        False\n","â”‚    â”‚    â””â”€Conv2d (conv1)               [32, 64, 56, 56]          [32, 64, 56, 56]          (4,096)                   False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn1)            [32, 64, 56, 56]          [32, 64, 56, 56]          (128)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv2)               [32, 64, 56, 56]          [32, 64, 56, 56]          (36,864)                  False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn2)            [32, 64, 56, 56]          [32, 64, 56, 56]          (128)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv3)               [32, 64, 56, 56]          [32, 256, 56, 56]         (16,384)                  False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn3)            [32, 256, 56, 56]         [32, 256, 56, 56]         (512)                     False\n","â”‚    â”‚    â””â”€Sequential (downsample)      [32, 64, 56, 56]          [32, 256, 56, 56]         (16,896)                  False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 256, 56, 56]         [32, 256, 56, 56]         --                        --\n","â”‚    â””â”€Bottleneck (1)                    [32, 256, 56, 56]         [32, 256, 56, 56]         --                        False\n","â”‚    â”‚    â””â”€Conv2d (conv1)               [32, 256, 56, 56]         [32, 64, 56, 56]          (16,384)                  False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn1)            [32, 64, 56, 56]          [32, 64, 56, 56]          (128)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv2)               [32, 64, 56, 56]          [32, 64, 56, 56]          (36,864)                  False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn2)            [32, 64, 56, 56]          [32, 64, 56, 56]          (128)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv3)               [32, 64, 56, 56]          [32, 256, 56, 56]         (16,384)                  False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn3)            [32, 256, 56, 56]         [32, 256, 56, 56]         (512)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 256, 56, 56]         [32, 256, 56, 56]         --                        --\n","â”‚    â””â”€Bottleneck (2)                    [32, 256, 56, 56]         [32, 256, 56, 56]         --                        False\n","â”‚    â”‚    â””â”€Conv2d (conv1)               [32, 256, 56, 56]         [32, 64, 56, 56]          (16,384)                  False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn1)            [32, 64, 56, 56]          [32, 64, 56, 56]          (128)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv2)               [32, 64, 56, 56]          [32, 64, 56, 56]          (36,864)                  False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn2)            [32, 64, 56, 56]          [32, 64, 56, 56]          (128)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv3)               [32, 64, 56, 56]          [32, 256, 56, 56]         (16,384)                  False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn3)            [32, 256, 56, 56]         [32, 256, 56, 56]         (512)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 256, 56, 56]         [32, 256, 56, 56]         --                        --\n","â”œâ”€Sequential (layer2)                    [32, 256, 56, 56]         [32, 512, 28, 28]         --                        False\n","â”‚    â””â”€Bottleneck (0)                    [32, 256, 56, 56]         [32, 512, 28, 28]         --                        False\n","â”‚    â”‚    â””â”€Conv2d (conv1)               [32, 256, 56, 56]         [32, 128, 56, 56]         (32,768)                  False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn1)            [32, 128, 56, 56]         [32, 128, 56, 56]         (256)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 128, 56, 56]         [32, 128, 56, 56]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv2)               [32, 128, 56, 56]         [32, 128, 28, 28]         (147,456)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn2)            [32, 128, 28, 28]         [32, 128, 28, 28]         (256)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv3)               [32, 128, 28, 28]         [32, 512, 28, 28]         (65,536)                  False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn3)            [32, 512, 28, 28]         [32, 512, 28, 28]         (1,024)                   False\n","â”‚    â”‚    â””â”€Sequential (downsample)      [32, 256, 56, 56]         [32, 512, 28, 28]         (132,096)                 False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 512, 28, 28]         [32, 512, 28, 28]         --                        --\n","â”‚    â””â”€Bottleneck (1)                    [32, 512, 28, 28]         [32, 512, 28, 28]         --                        False\n","â”‚    â”‚    â””â”€Conv2d (conv1)               [32, 512, 28, 28]         [32, 128, 28, 28]         (65,536)                  False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn1)            [32, 128, 28, 28]         [32, 128, 28, 28]         (256)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv2)               [32, 128, 28, 28]         [32, 128, 28, 28]         (147,456)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn2)            [32, 128, 28, 28]         [32, 128, 28, 28]         (256)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv3)               [32, 128, 28, 28]         [32, 512, 28, 28]         (65,536)                  False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn3)            [32, 512, 28, 28]         [32, 512, 28, 28]         (1,024)                   False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 512, 28, 28]         [32, 512, 28, 28]         --                        --\n","â”‚    â””â”€Bottleneck (2)                    [32, 512, 28, 28]         [32, 512, 28, 28]         --                        False\n","â”‚    â”‚    â””â”€Conv2d (conv1)               [32, 512, 28, 28]         [32, 128, 28, 28]         (65,536)                  False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn1)            [32, 128, 28, 28]         [32, 128, 28, 28]         (256)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv2)               [32, 128, 28, 28]         [32, 128, 28, 28]         (147,456)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn2)            [32, 128, 28, 28]         [32, 128, 28, 28]         (256)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv3)               [32, 128, 28, 28]         [32, 512, 28, 28]         (65,536)                  False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn3)            [32, 512, 28, 28]         [32, 512, 28, 28]         (1,024)                   False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 512, 28, 28]         [32, 512, 28, 28]         --                        --\n","â”‚    â””â”€Bottleneck (3)                    [32, 512, 28, 28]         [32, 512, 28, 28]         --                        False\n","â”‚    â”‚    â””â”€Conv2d (conv1)               [32, 512, 28, 28]         [32, 128, 28, 28]         (65,536)                  False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn1)            [32, 128, 28, 28]         [32, 128, 28, 28]         (256)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv2)               [32, 128, 28, 28]         [32, 128, 28, 28]         (147,456)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn2)            [32, 128, 28, 28]         [32, 128, 28, 28]         (256)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv3)               [32, 128, 28, 28]         [32, 512, 28, 28]         (65,536)                  False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn3)            [32, 512, 28, 28]         [32, 512, 28, 28]         (1,024)                   False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 512, 28, 28]         [32, 512, 28, 28]         --                        --\n","â”œâ”€Sequential (layer3)                    [32, 512, 28, 28]         [32, 1024, 14, 14]        --                        False\n","â”‚    â””â”€Bottleneck (0)                    [32, 512, 28, 28]         [32, 1024, 14, 14]        --                        False\n","â”‚    â”‚    â””â”€Conv2d (conv1)               [32, 512, 28, 28]         [32, 256, 28, 28]         (131,072)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn1)            [32, 256, 28, 28]         [32, 256, 28, 28]         (512)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 256, 28, 28]         [32, 256, 28, 28]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv2)               [32, 256, 28, 28]         [32, 256, 14, 14]         (589,824)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn2)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv3)               [32, 256, 14, 14]         [32, 1024, 14, 14]        (262,144)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn3)            [32, 1024, 14, 14]        [32, 1024, 14, 14]        (2,048)                   False\n","â”‚    â”‚    â””â”€Sequential (downsample)      [32, 512, 28, 28]         [32, 1024, 14, 14]        (526,336)                 False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        --\n","â”‚    â””â”€Bottleneck (1)                    [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        False\n","â”‚    â”‚    â””â”€Conv2d (conv1)               [32, 1024, 14, 14]        [32, 256, 14, 14]         (262,144)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn1)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv2)               [32, 256, 14, 14]         [32, 256, 14, 14]         (589,824)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn2)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv3)               [32, 256, 14, 14]         [32, 1024, 14, 14]        (262,144)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn3)            [32, 1024, 14, 14]        [32, 1024, 14, 14]        (2,048)                   False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        --\n","â”‚    â””â”€Bottleneck (2)                    [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        False\n","â”‚    â”‚    â””â”€Conv2d (conv1)               [32, 1024, 14, 14]        [32, 256, 14, 14]         (262,144)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn1)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv2)               [32, 256, 14, 14]         [32, 256, 14, 14]         (589,824)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn2)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv3)               [32, 256, 14, 14]         [32, 1024, 14, 14]        (262,144)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn3)            [32, 1024, 14, 14]        [32, 1024, 14, 14]        (2,048)                   False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        --\n","â”‚    â””â”€Bottleneck (3)                    [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        False\n","â”‚    â”‚    â””â”€Conv2d (conv1)               [32, 1024, 14, 14]        [32, 256, 14, 14]         (262,144)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn1)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv2)               [32, 256, 14, 14]         [32, 256, 14, 14]         (589,824)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn2)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv3)               [32, 256, 14, 14]         [32, 1024, 14, 14]        (262,144)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn3)            [32, 1024, 14, 14]        [32, 1024, 14, 14]        (2,048)                   False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        --\n","â”‚    â””â”€Bottleneck (4)                    [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        False\n","â”‚    â”‚    â””â”€Conv2d (conv1)               [32, 1024, 14, 14]        [32, 256, 14, 14]         (262,144)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn1)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv2)               [32, 256, 14, 14]         [32, 256, 14, 14]         (589,824)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn2)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv3)               [32, 256, 14, 14]         [32, 1024, 14, 14]        (262,144)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn3)            [32, 1024, 14, 14]        [32, 1024, 14, 14]        (2,048)                   False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        --\n","â”‚    â””â”€Bottleneck (5)                    [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        False\n","â”‚    â”‚    â””â”€Conv2d (conv1)               [32, 1024, 14, 14]        [32, 256, 14, 14]         (262,144)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn1)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv2)               [32, 256, 14, 14]         [32, 256, 14, 14]         (589,824)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn2)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv3)               [32, 256, 14, 14]         [32, 1024, 14, 14]        (262,144)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn3)            [32, 1024, 14, 14]        [32, 1024, 14, 14]        (2,048)                   False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        --\n","â”œâ”€Sequential (layer4)                    [32, 1024, 14, 14]        [32, 2048, 7, 7]          --                        False\n","â”‚    â””â”€Bottleneck (0)                    [32, 1024, 14, 14]        [32, 2048, 7, 7]          --                        False\n","â”‚    â”‚    â””â”€Conv2d (conv1)               [32, 1024, 14, 14]        [32, 512, 14, 14]         (524,288)                 False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn1)            [32, 512, 14, 14]         [32, 512, 14, 14]         (1,024)                   False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 512, 14, 14]         [32, 512, 14, 14]         --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv2)               [32, 512, 14, 14]         [32, 512, 7, 7]           (2,359,296)               False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn2)            [32, 512, 7, 7]           [32, 512, 7, 7]           (1,024)                   False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv3)               [32, 512, 7, 7]           [32, 2048, 7, 7]          (1,048,576)               False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn3)            [32, 2048, 7, 7]          [32, 2048, 7, 7]          (4,096)                   False\n","â”‚    â”‚    â””â”€Sequential (downsample)      [32, 1024, 14, 14]        [32, 2048, 7, 7]          (2,101,248)               False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 2048, 7, 7]          [32, 2048, 7, 7]          --                        --\n","â”‚    â””â”€Bottleneck (1)                    [32, 2048, 7, 7]          [32, 2048, 7, 7]          --                        False\n","â”‚    â”‚    â””â”€Conv2d (conv1)               [32, 2048, 7, 7]          [32, 512, 7, 7]           (1,048,576)               False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn1)            [32, 512, 7, 7]           [32, 512, 7, 7]           (1,024)                   False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv2)               [32, 512, 7, 7]           [32, 512, 7, 7]           (2,359,296)               False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn2)            [32, 512, 7, 7]           [32, 512, 7, 7]           (1,024)                   False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv3)               [32, 512, 7, 7]           [32, 2048, 7, 7]          (1,048,576)               False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn3)            [32, 2048, 7, 7]          [32, 2048, 7, 7]          (4,096)                   False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 2048, 7, 7]          [32, 2048, 7, 7]          --                        --\n","â”‚    â””â”€Bottleneck (2)                    [32, 2048, 7, 7]          [32, 2048, 7, 7]          --                        False\n","â”‚    â”‚    â””â”€Conv2d (conv1)               [32, 2048, 7, 7]          [32, 512, 7, 7]           (1,048,576)               False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn1)            [32, 512, 7, 7]           [32, 512, 7, 7]           (1,024)                   False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv2)               [32, 512, 7, 7]           [32, 512, 7, 7]           (2,359,296)               False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn2)            [32, 512, 7, 7]           [32, 512, 7, 7]           (1,024)                   False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n","â”‚    â”‚    â””â”€Conv2d (conv3)               [32, 512, 7, 7]           [32, 2048, 7, 7]          (1,048,576)               False\n","â”‚    â”‚    â””â”€BatchNorm2d (bn3)            [32, 2048, 7, 7]          [32, 2048, 7, 7]          (4,096)                   False\n","â”‚    â”‚    â””â”€ReLU (relu)                  [32, 2048, 7, 7]          [32, 2048, 7, 7]          --                        --\n","â”œâ”€AdaptiveAvgPool2d (avgpool)            [32, 2048, 7, 7]          [32, 2048, 1, 1]          --                        --\n","â”œâ”€Sequential (fc)                        [32, 2048]                [32, 36]                  --                        True\n","â”‚    â””â”€Dropout (0)                       [32, 2048]                [32, 2048]                --                        --\n","â”‚    â””â”€Linear (1)                        [32, 2048]                [32, 36]                  73,764                    True\n","============================================================================================================================================\n","Total params: 23,581,796\n","Trainable params: 73,764\n","Non-trainable params: 23,508,032\n","Total mult-adds (Units.GIGABYTES): 130.79\n","============================================================================================================================================\n","Input size (MB): 19.27\n","Forward/backward pass size (MB): 5690.37\n","Params size (MB): 94.33\n","Estimated Total Size (MB): 5803.96\n","============================================================================================================================================"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["## 06 Training"],"metadata":{"id":"GTb6cKqF83it"}},{"cell_type":"code","source":["def train_step(model: torch.nn.Module,\n","               dataloader: torch.utils.data.DataLoader,\n","               loss_fn: torch.nn.Module,\n","               optimizer: torch.optim.Optimizer,\n","               device: torch.device) -> Tuple[float, float]:\n","    \"\"\"\n","    ë‹¨ì¼ í•™ìŠµ ìŠ¤í…ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜\n","    \"\"\"\n","    model.train()  # í•™ìŠµ ëª¨ë“œ ì„¤ì •\n","    train_loss, train_acc = 0, 0  # í•™ìŠµ ì†ì‹¤ ë° ì •í™•ë„ ì´ˆê¸°í™”\n","\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)  # ì…ë ¥ ë°ì´í„°ì™€ ë¼ë²¨ì„ ì§€ì •ëœ ì¥ì¹˜ë¡œ ì´ë™\n","        optimizer.zero_grad()  # ì´ì „ ë‹¨ê³„ì˜ ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”\n","        y_pred = model(X)  # ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰\n","        loss = loss_fn(y_pred, y)  # ì†ì‹¤ ê³„ì‚°\n","        loss.backward()  # ì—­ì „íŒŒ(Backpropagation)\n","        optimizer.step()  # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n","\n","        train_loss += loss.item()  # ì†ì‹¤ í•©ì‚°\n","        acc = (y_pred.argmax(dim=1) == y).sum().item() / len(y)  # ì •í™•ë„ ê³„ì‚°\n","        train_acc += acc  # ì •í™•ë„ í•©ì‚°\n","\n","    return train_loss / len(dataloader), train_acc / len(dataloader)  # í‰ê·  ì†ì‹¤ ë° ì •í™•ë„ ë°˜í™˜\n","\n","\n","def eval_step(model: torch.nn.Module,\n","              dataloader: torch.utils.data.DataLoader,\n","              loss_fn: torch.nn.Module,\n","              device: torch.device) -> Tuple[float, float]:\n","    \"\"\"\n","    ë‹¨ì¼ í‰ê°€ ìŠ¤í…ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜\n","    \"\"\"\n","    model.eval()  # í‰ê°€ ëª¨ë“œ ì„¤ì •\n","    eval_loss, eval_acc = 0, 0  # í‰ê°€ ì†ì‹¤ ë° ì •í™•ë„ ì´ˆê¸°í™”\n","\n","    with torch.inference_mode():  # í‰ê°€ ì‹œ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™” (ì†ë„ í–¥ìƒ)\n","        for batch, (X, y) in enumerate(dataloader):\n","            X, y = X.to(device), y.to(device)  # ì…ë ¥ ë°ì´í„°ì™€ ë¼ë²¨ì„ ì§€ì •ëœ ì¥ì¹˜ë¡œ ì´ë™\n","            y_pred = model(X)  # ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰\n","            loss = loss_fn(y_pred, y)  # ì†ì‹¤ ê³„ì‚°\n","            eval_loss += loss.item()  # ì†ì‹¤ í•©ì‚°\n","            acc = (y_pred.argmax(dim=1) == y).sum().item() / len(y)  # ì •í™•ë„ ê³„ì‚°\n","            eval_acc += acc  # ì •í™•ë„ í•©ì‚°\n","\n","    return eval_loss / len(dataloader), eval_acc / len(dataloader)  # í‰ê·  ì†ì‹¤ ë° ì •í™•ë„ ë°˜í™˜\n","\n","\n","def train_eval(model: torch.nn.Module,\n","               train_dataloader: torch.utils.data.DataLoader,\n","               val_dataloader: torch.utils.data.DataLoader,\n","               epochs: int,\n","               loss_fn: torch.nn.Module,\n","               optimizer: torch.optim.Optimizer,\n","               device: torch.device) -> List[Dict[str, float]]:\n","    \"\"\"\n","    ì§€ì •ëœ ì—í¬í¬(epochs) ë™ì•ˆ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê°€í•˜ëŠ” í•¨ìˆ˜\n","    \"\"\"\n","    results = []  # í•™ìŠµ ë° í‰ê°€ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n","\n","    # ì „ì²´ í•™ìŠµ ì‹œì‘ ì‹œê°„ ê¸°ë¡\n","    total_start_time = time.time()\n","\n","    for epoch in range(epochs):\n","        # í•™ìŠµ ë‹¨ê³„ ìˆ˜í–‰\n","        train_loss, train_acc = train_step(model, train_dataloader, loss_fn, optimizer, device)\n","        # í‰ê°€ ë‹¨ê³„ ìˆ˜í–‰\n","        val_loss, val_acc = eval_step(model, val_dataloader, loss_fn, device)\n","\n","        # í˜„ì¬ í•™ìŠµë¥  í™•ì¸\n","        current_lr = optimizer.param_groups[0]['lr']\n","\n","        # í•™ìŠµ ë° í‰ê°€ ê²°ê³¼ ì¶œë ¥\n","        print(f\"Epoch {epoch+1}/{epochs}: \\n\"\n","              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} \\n\"\n","              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | LR: {current_lr:.6f}\")\n","\n","        # ê²°ê³¼ ì €ì¥\n","        results.append({\n","            \"epoch\": epoch+1,\n","            \"Train_loss\": train_loss,\n","            \"Train_acc\": train_acc,\n","            \"Val_loss\": val_loss,\n","            \"Val_acc\": val_acc,\n","            \"lr\": current_lr\n","        })\n","\n","    # ì „ì²´ í•™ìŠµ ë ì‹œê°„ ê¸°ë¡\n","    total_end_time = time.time()\n","    total_minutes = (total_end_time - total_start_time) / 60\n","\n","    print(f\"\\nğŸ•’ ì „ì²´ í•™ìŠµ ì‹œê°„: {total_minutes:.2f}ë¶„\")\n","\n","    return results"],"metadata":{"id":"H--aT8R1866W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### train()"],"metadata":{"id":"dp0Ex7zKBKrS"}},{"cell_type":"code","source":["# ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”\n","loss_fn = nn.CrossEntropyLoss()  # ë‹¤ì¤‘ ë¶„ë¥˜ ë¬¸ì œì— ì í•©í•œ í¬ë¡œìŠ¤ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ í•¨ìˆ˜ ì‚¬ìš©\n","optimizer = optim.Adam(params=ResNet_model.parameters(), lr=0.001, weight_decay=0.0001)  # Adam ì˜µí‹°ë§ˆì´ì € ì‚¬ìš©, í•™ìŠµë¥ (lr) ì„¤ì •\n","\n","# í•™ìŠµí•  ì´ ì—í¬í¬ ìˆ˜ ì„¤ì •\n","NUM_EPOCHS = 50\n","\n","# í•™ìŠµ ì‹¤í–‰\n","results = train_eval(model=ResNet_model,\n","                     train_dataloader=train_dataloader,\n","                     val_dataloader=validation_dataloader,\n","                     epochs=NUM_EPOCHS,\n","                     loss_fn=loss_fn,\n","                     optimizer=optimizer,\n","                     device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4WB-cTuvVyNY","outputId":"75c89973-14cb-4d58-a19b-05baaeb580fc","executionInfo":{"status":"ok","timestamp":1743313871030,"user_tz":-540,"elapsed":2826231,"user":{"displayName":"ì´ìˆ˜ì¸","userId":"16249151905029041959"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50: \n","Train Loss: 1.8686 | Train Acc: 0.6470 \n","Val Loss: 0.7285 | Val Acc: 0.8889 | LR: 0.001000\n","Epoch 2/50: \n","Train Loss: 0.7845 | Train Acc: 0.8430 \n","Val Loss: 0.4207 | Val Acc: 0.9289 | LR: 0.001000\n","Epoch 3/50: \n","Train Loss: 0.5523 | Train Acc: 0.8772 \n","Val Loss: 0.3141 | Val Acc: 0.9332 | LR: 0.001000\n","Epoch 4/50: \n","Train Loss: 0.4446 | Train Acc: 0.9015 \n","Val Loss: 0.2666 | Val Acc: 0.9304 | LR: 0.001000\n","Epoch 5/50: \n","Train Loss: 0.3670 | Train Acc: 0.9174 \n","Val Loss: 0.2277 | Val Acc: 0.9529 | LR: 0.001000\n","Epoch 6/50: \n","Train Loss: 0.3196 | Train Acc: 0.9269 \n","Val Loss: 0.2110 | Val Acc: 0.9444 | LR: 0.001000\n","Epoch 7/50: \n","Train Loss: 0.2955 | Train Acc: 0.9277 \n","Val Loss: 0.1860 | Val Acc: 0.9616 | LR: 0.001000\n","Epoch 8/50: \n","Train Loss: 0.2641 | Train Acc: 0.9377 \n","Val Loss: 0.1784 | Val Acc: 0.9574 | LR: 0.001000\n","Epoch 9/50: \n","Train Loss: 0.2390 | Train Acc: 0.9481 \n","Val Loss: 0.1850 | Val Acc: 0.9445 | LR: 0.001000\n","Epoch 10/50: \n","Train Loss: 0.2231 | Train Acc: 0.9474 \n","Val Loss: 0.1629 | Val Acc: 0.9574 | LR: 0.001000\n","Epoch 11/50: \n","Train Loss: 0.2082 | Train Acc: 0.9463 \n","Val Loss: 0.1591 | Val Acc: 0.9545 | LR: 0.001000\n","Epoch 12/50: \n","Train Loss: 0.1897 | Train Acc: 0.9559 \n","Val Loss: 0.1619 | Val Acc: 0.9488 | LR: 0.001000\n","Epoch 13/50: \n","Train Loss: 0.1903 | Train Acc: 0.9519 \n","Val Loss: 0.1562 | Val Acc: 0.9503 | LR: 0.001000\n","Epoch 14/50: \n","Train Loss: 0.1744 | Train Acc: 0.9551 \n","Val Loss: 0.1587 | Val Acc: 0.9560 | LR: 0.001000\n","Epoch 15/50: \n","Train Loss: 0.1696 | Train Acc: 0.9551 \n","Val Loss: 0.1670 | Val Acc: 0.9545 | LR: 0.001000\n","Epoch 16/50: \n","Train Loss: 0.1631 | Train Acc: 0.9614 \n","Val Loss: 0.1572 | Val Acc: 0.9560 | LR: 0.001000\n","Epoch 17/50: \n","Train Loss: 0.1554 | Train Acc: 0.9629 \n","Val Loss: 0.1666 | Val Acc: 0.9488 | LR: 0.001000\n","Epoch 18/50: \n","Train Loss: 0.1524 | Train Acc: 0.9635 \n","Val Loss: 0.1473 | Val Acc: 0.9574 | LR: 0.001000\n","Epoch 19/50: \n","Train Loss: 0.1458 | Train Acc: 0.9648 \n","Val Loss: 0.1479 | Val Acc: 0.9574 | LR: 0.001000\n","Epoch 20/50: \n","Train Loss: 0.1423 | Train Acc: 0.9639 \n","Val Loss: 0.1476 | Val Acc: 0.9631 | LR: 0.001000\n","Epoch 21/50: \n","Train Loss: 0.1369 | Train Acc: 0.9668 \n","Val Loss: 0.1409 | Val Acc: 0.9616 | LR: 0.001000\n","Epoch 22/50: \n","Train Loss: 0.1319 | Train Acc: 0.9649 \n","Val Loss: 0.1417 | Val Acc: 0.9574 | LR: 0.001000\n","Epoch 23/50: \n","Train Loss: 0.1308 | Train Acc: 0.9676 \n","Val Loss: 0.1377 | Val Acc: 0.9616 | LR: 0.001000\n","Epoch 24/50: \n","Train Loss: 0.1307 | Train Acc: 0.9672 \n","Val Loss: 0.1236 | Val Acc: 0.9616 | LR: 0.001000\n","Epoch 25/50: \n","Train Loss: 0.1309 | Train Acc: 0.9655 \n","Val Loss: 0.1366 | Val Acc: 0.9659 | LR: 0.001000\n","Epoch 26/50: \n","Train Loss: 0.1293 | Train Acc: 0.9647 \n","Val Loss: 0.1488 | Val Acc: 0.9588 | LR: 0.001000\n","Epoch 27/50: \n","Train Loss: 0.1206 | Train Acc: 0.9683 \n","Val Loss: 0.1352 | Val Acc: 0.9602 | LR: 0.001000\n","Epoch 28/50: \n","Train Loss: 0.1212 | Train Acc: 0.9682 \n","Val Loss: 0.1425 | Val Acc: 0.9631 | LR: 0.001000\n","Epoch 29/50: \n","Train Loss: 0.1093 | Train Acc: 0.9744 \n","Val Loss: 0.1472 | Val Acc: 0.9545 | LR: 0.001000\n","Epoch 30/50: \n","Train Loss: 0.1185 | Train Acc: 0.9660 \n","Val Loss: 0.1440 | Val Acc: 0.9659 | LR: 0.001000\n","Epoch 31/50: \n","Train Loss: 0.1133 | Train Acc: 0.9717 \n","Val Loss: 0.1248 | Val Acc: 0.9631 | LR: 0.001000\n","Epoch 32/50: \n","Train Loss: 0.1144 | Train Acc: 0.9680 \n","Val Loss: 0.1398 | Val Acc: 0.9644 | LR: 0.001000\n","Epoch 33/50: \n","Train Loss: 0.1162 | Train Acc: 0.9677 \n","Val Loss: 0.1296 | Val Acc: 0.9560 | LR: 0.001000\n","Epoch 34/50: \n","Train Loss: 0.1137 | Train Acc: 0.9716 \n","Val Loss: 0.1332 | Val Acc: 0.9631 | LR: 0.001000\n","Epoch 35/50: \n","Train Loss: 0.1141 | Train Acc: 0.9661 \n","Val Loss: 0.1323 | Val Acc: 0.9659 | LR: 0.001000\n","Epoch 36/50: \n","Train Loss: 0.1109 | Train Acc: 0.9723 \n","Val Loss: 0.1310 | Val Acc: 0.9588 | LR: 0.001000\n","Epoch 37/50: \n","Train Loss: 0.1067 | Train Acc: 0.9737 \n","Val Loss: 0.1275 | Val Acc: 0.9631 | LR: 0.001000\n","Epoch 38/50: \n","Train Loss: 0.1073 | Train Acc: 0.9713 \n","Val Loss: 0.1299 | Val Acc: 0.9602 | LR: 0.001000\n","Epoch 39/50: \n","Train Loss: 0.1029 | Train Acc: 0.9725 \n","Val Loss: 0.1312 | Val Acc: 0.9702 | LR: 0.001000\n","Epoch 40/50: \n","Train Loss: 0.1067 | Train Acc: 0.9700 \n","Val Loss: 0.1310 | Val Acc: 0.9688 | LR: 0.001000\n","Epoch 41/50: \n","Train Loss: 0.1128 | Train Acc: 0.9673 \n","Val Loss: 0.1292 | Val Acc: 0.9645 | LR: 0.001000\n","Epoch 42/50: \n","Train Loss: 0.1055 | Train Acc: 0.9697 \n","Val Loss: 0.1343 | Val Acc: 0.9645 | LR: 0.001000\n","Epoch 43/50: \n","Train Loss: 0.1001 | Train Acc: 0.9764 \n","Val Loss: 0.1281 | Val Acc: 0.9644 | LR: 0.001000\n","Epoch 44/50: \n","Train Loss: 0.0989 | Train Acc: 0.9728 \n","Val Loss: 0.1178 | Val Acc: 0.9645 | LR: 0.001000\n","Epoch 45/50: \n","Train Loss: 0.1029 | Train Acc: 0.9719 \n","Val Loss: 0.1185 | Val Acc: 0.9602 | LR: 0.001000\n","Epoch 46/50: \n","Train Loss: 0.1031 | Train Acc: 0.9694 \n","Val Loss: 0.1284 | Val Acc: 0.9631 | LR: 0.001000\n","Epoch 47/50: \n","Train Loss: 0.1011 | Train Acc: 0.9726 \n","Val Loss: 0.1336 | Val Acc: 0.9588 | LR: 0.001000\n","Epoch 48/50: \n","Train Loss: 0.1076 | Train Acc: 0.9689 \n","Val Loss: 0.1246 | Val Acc: 0.9645 | LR: 0.001000\n","Epoch 49/50: \n","Train Loss: 0.0994 | Train Acc: 0.9744 \n","Val Loss: 0.1243 | Val Acc: 0.9688 | LR: 0.001000\n","Epoch 50/50: \n","Train Loss: 0.1105 | Train Acc: 0.9697 \n","Val Loss: 0.1232 | Val Acc: 0.9645 | LR: 0.001000\n","\n","ğŸ•’ ì „ì²´ í•™ìŠµ ì‹œê°„: 47.10ë¶„\n"]}]},{"cell_type":"markdown","source":["## 07 Result"],"metadata":{"id":"nizwunc-T_he"}},{"cell_type":"code","source":["# ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜\n","results_df = pd.DataFrame(results)"],"metadata":{"id":"WGNESaqNKDgv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# í…ŒìŠ¤íŠ¸ ì…‹ í‰ê°€\n","test_loss, test_acc = eval_step(model=ResNet_model,\n","                                dataloader=test_dataloader,\n","                                loss_fn=loss_fn,\n","                                device=device)"],"metadata":{"id":"F1_84555J13C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ê²°ê³¼\n","print(f\"Test accuracy: {test_acc:.6f}\")\n","print(f\"Test Loss: {test_loss:.6f}\")"],"metadata":{"id":"cbyA64udJ3JD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743313896569,"user_tz":-540,"elapsed":20,"user":{"displayName":"ì´ìˆ˜ì¸","userId":"16249151905029041959"}},"outputId":"ed8075b3-8e86-4732-ca5b-dc841bf96a2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy: 0.968750\n","Test Loss: 0.104553\n"]}]},{"cell_type":"code","source":["# Test accuracy: 0.971354\n","# Test Loss: 0.098235"],"metadata":{"id":"VbGLdQ7zHutr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 08 DB ì €ì¥"],"metadata":{"id":"_lLjAY5N7d5k"}},{"cell_type":"code","source":["from sqlalchemy import create_engine\n","\n","# DB ì—°ê²° ì •ë³´ ì…ë ¥ (Aiven MySQL ê¸°ì¤€)\n","host = 'YOUR_AIVEN_HOST'\n","port = 'YOUR_AIVEN_PORT'\n","username = 'YOUR_USERNAME'\n","password = 'YOUR_PASSWORD'\n","database = 'YOUR_DATABASE'\n","\n","# SQLAlchemy ì—”ì§„ ìƒì„±\n","engine = create_engine(f\"mysql+pymysql://{username}:{password}@{host}:{port}/{database}\")\n","# DataFrameì„ MySQLì— ì €ì¥\n","results_df.to_sql(name='train_logs_resnet', con=engine, if_exists='append', index=False)\n","\n","# í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n","test_result_df = pd.DataFrame([{\n","    \"model_name\": \"ResNet50\",\n","    \"test_loss\": test_loss,\n","    \"test_acc\": test_acc\n","}])\n","\n","test_result_df.to_sql(name='test_results', con=engine, if_exists='append', index=False)"],"metadata":{"id":"49bcl37v7fir","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743313897578,"user_tz":-540,"elapsed":1007,"user":{"displayName":"ì´ìˆ˜ì¸","userId":"16249151905029041959"}},"outputId":"b2be6972-d035-41e6-fdc0-ce78c0b579fb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":15}]}]}