{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","toc_visible":true,"mount_file_id":"14fUFS_IT3-IWAgnBkKyDJMt0sQX4dj-i","authorship_tag":"ABX9TyOQTum+YHXdSi9ecAtgB4Vv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## 00 Install"],"metadata":{"id":"wfjalG9B24DQ"}},{"cell_type":"code","source":["# !pip install torchinfo\n","# !pip install modules\n","# !pip install pymysql sqlalchemy"],"metadata":{"id":"0RSLLBJc22tE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 01 Import"],"metadata":{"id":"acjiRtJN7oJ6"}},{"cell_type":"code","source":["# import libraries\n","import os\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import os.path\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import time\n","\n","import torch\n","import torchvision\n","from torchvision import models\n","from torch import nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import ImageFolder\n","from torchinfo import summary\n","import torchvision.transforms as transforms\n","\n","from pathlib import Path\n","from typing import Tuple, List, Dict, Optional\n","import random\n","from PIL import Image, ImageDraw\n","from torchvision.utils import make_grid\n","\n","# 디바이스 설정\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"sedXL5wU28a8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 02 Load Dataset"],"metadata":{"id":"HaUAiihp8Xii"}},{"cell_type":"code","source":["# 데이터 경로 설정\n","data_dir = 'your_path/fruit-and-vegetable-image'\n","\n","# 데이터 불러오기\n","train_dir = os.path.join(data_dir, 'train')\n","train_filepaths = list(Path(train_dir).rglob('*.jpg')) + \\\n","                  list(Path(train_dir).rglob('*.jpeg')) + \\\n","                  list(Path(train_dir).rglob('*.png')) + \\\n","                  list(Path(train_dir).rglob('*.JPG'))\n","\n","test_dir = os.path.join(data_dir, 'test')\n","test_filepaths = list(Path(test_dir).rglob('*.jpg')) + \\\n","                 list(Path(test_dir).rglob('*.jpeg')) + \\\n","                 list(Path(test_dir).rglob('*.png')) + \\\n","                 list(Path(test_dir).rglob('*.JPG'))\n","\n","val_dir = os.path.join(data_dir, 'validation')\n","val_filepaths = list(Path(val_dir).rglob('*.jpg')) + \\\n","                 list(Path(val_dir).rglob('*.jpeg')) + \\\n","                 list(Path(val_dir).rglob('*.png')) + \\\n","                 list(Path(val_dir).rglob('*.JPG'))\n","\n","\n","def proc_img(filepath):\n","    \"\"\"\n","    이미지 파일의 경로와 라벨을 포함하는 DataFrame을 생성하는 함수\n","    \"\"\"\n","\n","    # 파일 경로에서 라벨(폴더명) 추출\n","    labels = [str(filepath[i]).split(\"/\")[-2] for i in range(len(filepath))]\n","\n","    # 파일 경로를 pandas Series로 변환하고 문자열로 저장\n","    filepath = pd.Series(filepath, name='Filepath').astype(str)\n","\n","    # 라벨을 pandas Series로 변환\n","    labels = pd.Series(labels, name='Label')\n","\n","    # 파일 경로와 라벨을 하나의 DataFrame으로 합치기\n","    df = pd.concat([filepath, labels], axis=1)\n","\n","    # 데이터 프레임을 랜덤하게 섞고 인덱스 초기화\n","    df = df.sample(frac=1).reset_index(drop=True)\n","\n","    return df\n","\n","# 학습(train), 테스트(test), 검증(validation) 데이터 프레임 생성\n","train_df = proc_img(train_filepaths)\n","test_df = proc_img(test_filepaths)\n","val_df = proc_img(val_filepaths)\n","\n","# 클래스 목록 가져오기\n","class_labels = train_df.Label.unique()"],"metadata":{"id":"ZoWC8bz0lUpH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 03 Create Transformer"],"metadata":{"id":"KWap5H_13nm1"}},{"cell_type":"code","source":["# ResNet-18 모델의 기본 사전 학습된 가중치(Weights) 불러오기\n","ResNet_weights = models.ResNet50_Weights.DEFAULT\n","\n","# 해당 가중치에 맞는 변환(transform) 객체 가져오기\n","ResNet_transformer = ResNet_weights.transforms()  # 모델이 요구하는 데이터 전처리 파이프라인이 반환\n","\n","# 변환 객체 출력 (어떤 변환이 적용되는지 확인)\n","ResNet_transformer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"024RhS9w2csY","executionInfo":{"status":"ok","timestamp":1743311042142,"user_tz":-540,"elapsed":5,"user":{"displayName":"이수인","userId":"16249151905029041959"}},"outputId":"8f383431-505e-4ef1-f6e7-0b4f1c3e1221"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ImageClassification(\n","    crop_size=[224]\n","    resize_size=[232]\n","    mean=[0.485, 0.456, 0.406]\n","    std=[0.229, 0.224, 0.225]\n","    interpolation=InterpolationMode.BILINEAR\n",")"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# 랜덤한 사각형 노이즈 추가 함수\n","def add_rectangle_noise(image):\n","    \"\"\"이미지에 랜덤한 크기와 위치의 사각형 노이즈 추가\"\"\"\n","    draw = ImageDraw.Draw(image)\n","    width, height = image.size\n","\n","    # 노이즈 크기 (전체 이미지 크기의 30~50%)\n","    box_width = random.randint(int(0.3 * width), int(0.5 * width))\n","    box_height = random.randint(int(0.3 * height), int(0.5 * height))\n","\n","    # 랜덤 위치\n","    x1 = random.randint(0, width - box_width)\n","    y1 = random.randint(0, height - box_height)\n","    x2 = x1 + box_width\n","    y2 = y1 + box_height\n","\n","    # 랜덤 색상 (0~255 범위)\n","    noise_color = tuple(np.random.randint(0, 256, size=3).tolist())\n","\n","    # 사각형 그리기\n","    draw.rectangle([x1, y1, x2, y2], fill=noise_color)\n","    return image\n","\n","# 데이터셋 증강 및 변환 적용\n","augmented_transform = transforms.Compose([\n","    transforms.RandomRotation(20),  # -20도 ~ 20도 회전\n","    transforms.RandomHorizontalFlip(),  # 50% 확률로 좌우 반전\n","    transforms.Lambda(lambda img: add_rectangle_noise(img)),  # 랜덤한 사각형 노이즈 추가\n","    ResNet_transformer  # MobileNetV3 기본 변환 적용\n","])\n","\n","# 원본과 증강 데이터셋을 각각 생성\n","train_data_original = ImageFolder(root=train_dir, transform=ResNet_transformer)  # 원본 데이터\n","train_data_augmented = ImageFolder(root=train_dir, transform=augmented_transform)  # 증강 데이터\n","\n","validation_data_original = ImageFolder(root=val_dir, transform=ResNet_transformer)  # 검증 원본 데이터\n","validation_data_augmented = ImageFolder(root=val_dir, transform=augmented_transform)  # 검증 증강 데이터\n","\n","# 결합\n","train_data_transformed = torch.utils.data.ConcatDataset([train_data_original, train_data_augmented])\n","validation_data_transformed = torch.utils.data.ConcatDataset([validation_data_original, validation_data_augmented])\n","\n","print(f\"Original dataset size: {len(train_data_original)}\")\n","print(f\"Augmented dataset size: {len(train_data_augmented)}\")\n","print(f\"Combined dataset size: {len(train_data_transformed)}\")\n","print(f\"Validation dataset szie: {len(validation_data_transformed)}\")\n","\n","# 테스트 데이터는 원본 그대로 유지\n","test_data_transformed = ImageFolder(root=test_dir, transform=ResNet_transformer)\n","\n","# 변환된 데이터셋 확인\n","print(train_data_original, '\\n\\n', train_data_augmented)"],"metadata":{"id":"XBf_Bwysucgu","executionInfo":{"status":"ok","timestamp":1743311042240,"user_tz":-540,"elapsed":97,"user":{"displayName":"이수인","userId":"16249151905029041959"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"071f6512-d77a-4430-9ee0-e9730c76a55e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original dataset size: 3115\n","Augmented dataset size: 3115\n","Combined dataset size: 6230\n","Validation dataset szie: 702\n","Dataset ImageFolder\n","    Number of datapoints: 3115\n","    Root location: /content/drive/MyDrive/Colab_Notebooks/fruit-and-vegetable-image/train\n","    StandardTransform\n","Transform: ImageClassification(\n","               crop_size=[224]\n","               resize_size=[232]\n","               mean=[0.485, 0.456, 0.406]\n","               std=[0.229, 0.224, 0.225]\n","               interpolation=InterpolationMode.BILINEAR\n","           ) \n","\n"," Dataset ImageFolder\n","    Number of datapoints: 3115\n","    Root location: /content/drive/MyDrive/Colab_Notebooks/fruit-and-vegetable-image/train\n","    StandardTransform\n","Transform: Compose(\n","               RandomRotation(degrees=[-20.0, 20.0], interpolation=nearest, expand=False, fill=0)\n","               RandomHorizontalFlip(p=0.5)\n","               Lambda()\n","               ImageClassification(\n","               crop_size=[224]\n","               resize_size=[232]\n","               mean=[0.485, 0.456, 0.406]\n","               std=[0.229, 0.224, 0.225]\n","               interpolation=InterpolationMode.BILINEAR\n","           )\n","           )\n"]}]},{"cell_type":"markdown","source":["## 04 Dataloader"],"metadata":{"id":"PBJ1sO5a9oTk"}},{"cell_type":"code","source":["# 배치 크기 및 워커(worker) 수 설정\n","BATCH_SIZE = 32  # 한 번에 학습할 데이터 샘플 수\n","NUM_WORKERS = os.cpu_count()  # 사용할 CPU 코어 개수 (최대 성능 활용)\n","\n","# 학습 데이터 로더 생성\n","train_dataloader = DataLoader(dataset=train_data_transformed,  # 학습 데이터셋\n","                              batch_size=BATCH_SIZE,  # 배치 크기 설정\n","                              num_workers=NUM_WORKERS,  # CPU 워커 개수 설정\n","                              shuffle=True,  # 학습 데이터는 랜덤으로 섞어서 로드\n","                              pin_memory=True)  # CUDA 사용 시 메모리 핀 설정 (속도 향상)\n","\n","# 검증 데이터 로더 생성\n","validation_dataloader = DataLoader(dataset=validation_data_transformed,\n","                                   batch_size=BATCH_SIZE,\n","                                   num_workers=NUM_WORKERS,\n","                                   shuffle=False,\n","                                   pin_memory=True)\n","\n","# 테스트 데이터 로더 생성\n","test_dataloader = DataLoader(dataset=test_data_transformed,\n","                             batch_size=BATCH_SIZE,\n","                             num_workers=NUM_WORKERS,\n","                             shuffle=False,\n","                             pin_memory=True)"],"metadata":{"id":"5ZKAfXg840X0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 05 Modeling"],"metadata":{"id":"8LU-w3xJ7AcW"}},{"cell_type":"code","source":["# ResNet-50 모델 생성 및 사전 학습된 가중치 적용\n","ResNet_model = models.resnet50(weights=ResNet_weights).to(device)\n","\n","# 특징 추출기(Feature Extractor) 부분 동결\n","for param in ResNet_model.parameters():\n","    param.requires_grad = False  # 기존 가중치를 고정하여 학습되지 않도록 설정\n","\n","# 랜덤 시드 고정\n","torch.manual_seed(42) # 동일한 결과를 얻기 위해 랜덤 시드 설정 (CPU)\n","torch.cuda.manual_seed(42) # 동일한 결과를 얻기 위해 랜덤 시드 설정 (GPU)\n","\n","# 클래스 수 정의 (이미 정의된 class_labels 사용)\n","num_classes = len(class_labels)\n","\n","num_ftrs = ResNet_model.fc.in_features  # 기본적으로 ResNet-50의 fc는 2048 입력\n","\n","# 분류기(Classifier) 레이어 재구성\n","ResNet_model.fc = nn.Sequential(\n","    nn.Dropout(p=0.2, inplace=True), # 과적합 방지를 위한 드롭아웃 추가 (20% 확률로 뉴런 비활성화))\n","    nn.Linear(in_features=num_ftrs, out_features=len(class_labels)) # 출력 뉴런 수를 클래스 개수(len(class_labels))로 설정\n",")\n","\n","# 모델 디바이스 이동\n","ResNet_model = ResNet_model.to(device)\n","\n","# 모델의 구조를 다시 확인하여 변경된 부분을 확인\n","summary(model=ResNet_model,  # 모델 지정\n","        input_size=[32, 3, 224, 224],  # 입력 데이터 크기 (batch_size=32, 채널=3, 높이=224, 너비=224)\n","        col_names=['input_size', 'output_size', 'num_params', 'trainable'],  # 출력할 정보 설정\n","        row_settings=['var_names'])  # 변수명 출력"],"metadata":{"id":"-R9ilfFx7qQY","executionInfo":{"status":"ok","timestamp":1743311044759,"user_tz":-540,"elapsed":2513,"user":{"displayName":"이수인","userId":"16249151905029041959"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a8baf266-e41b-4220-aa5c-139e194a9b0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 174MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["============================================================================================================================================\n","Layer (type (var_name))                  Input Shape               Output Shape              Param #                   Trainable\n","============================================================================================================================================\n","ResNet (ResNet)                          [32, 3, 224, 224]         [32, 36]                  --                        Partial\n","├─Conv2d (conv1)                         [32, 3, 224, 224]         [32, 64, 112, 112]        (9,408)                   False\n","├─BatchNorm2d (bn1)                      [32, 64, 112, 112]        [32, 64, 112, 112]        (128)                     False\n","├─ReLU (relu)                            [32, 64, 112, 112]        [32, 64, 112, 112]        --                        --\n","├─MaxPool2d (maxpool)                    [32, 64, 112, 112]        [32, 64, 56, 56]          --                        --\n","├─Sequential (layer1)                    [32, 64, 56, 56]          [32, 256, 56, 56]         --                        False\n","│    └─Bottleneck (0)                    [32, 64, 56, 56]          [32, 256, 56, 56]         --                        False\n","│    │    └─Conv2d (conv1)               [32, 64, 56, 56]          [32, 64, 56, 56]          (4,096)                   False\n","│    │    └─BatchNorm2d (bn1)            [32, 64, 56, 56]          [32, 64, 56, 56]          (128)                     False\n","│    │    └─ReLU (relu)                  [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n","│    │    └─Conv2d (conv2)               [32, 64, 56, 56]          [32, 64, 56, 56]          (36,864)                  False\n","│    │    └─BatchNorm2d (bn2)            [32, 64, 56, 56]          [32, 64, 56, 56]          (128)                     False\n","│    │    └─ReLU (relu)                  [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n","│    │    └─Conv2d (conv3)               [32, 64, 56, 56]          [32, 256, 56, 56]         (16,384)                  False\n","│    │    └─BatchNorm2d (bn3)            [32, 256, 56, 56]         [32, 256, 56, 56]         (512)                     False\n","│    │    └─Sequential (downsample)      [32, 64, 56, 56]          [32, 256, 56, 56]         (16,896)                  False\n","│    │    └─ReLU (relu)                  [32, 256, 56, 56]         [32, 256, 56, 56]         --                        --\n","│    └─Bottleneck (1)                    [32, 256, 56, 56]         [32, 256, 56, 56]         --                        False\n","│    │    └─Conv2d (conv1)               [32, 256, 56, 56]         [32, 64, 56, 56]          (16,384)                  False\n","│    │    └─BatchNorm2d (bn1)            [32, 64, 56, 56]          [32, 64, 56, 56]          (128)                     False\n","│    │    └─ReLU (relu)                  [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n","│    │    └─Conv2d (conv2)               [32, 64, 56, 56]          [32, 64, 56, 56]          (36,864)                  False\n","│    │    └─BatchNorm2d (bn2)            [32, 64, 56, 56]          [32, 64, 56, 56]          (128)                     False\n","│    │    └─ReLU (relu)                  [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n","│    │    └─Conv2d (conv3)               [32, 64, 56, 56]          [32, 256, 56, 56]         (16,384)                  False\n","│    │    └─BatchNorm2d (bn3)            [32, 256, 56, 56]         [32, 256, 56, 56]         (512)                     False\n","│    │    └─ReLU (relu)                  [32, 256, 56, 56]         [32, 256, 56, 56]         --                        --\n","│    └─Bottleneck (2)                    [32, 256, 56, 56]         [32, 256, 56, 56]         --                        False\n","│    │    └─Conv2d (conv1)               [32, 256, 56, 56]         [32, 64, 56, 56]          (16,384)                  False\n","│    │    └─BatchNorm2d (bn1)            [32, 64, 56, 56]          [32, 64, 56, 56]          (128)                     False\n","│    │    └─ReLU (relu)                  [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n","│    │    └─Conv2d (conv2)               [32, 64, 56, 56]          [32, 64, 56, 56]          (36,864)                  False\n","│    │    └─BatchNorm2d (bn2)            [32, 64, 56, 56]          [32, 64, 56, 56]          (128)                     False\n","│    │    └─ReLU (relu)                  [32, 64, 56, 56]          [32, 64, 56, 56]          --                        --\n","│    │    └─Conv2d (conv3)               [32, 64, 56, 56]          [32, 256, 56, 56]         (16,384)                  False\n","│    │    └─BatchNorm2d (bn3)            [32, 256, 56, 56]         [32, 256, 56, 56]         (512)                     False\n","│    │    └─ReLU (relu)                  [32, 256, 56, 56]         [32, 256, 56, 56]         --                        --\n","├─Sequential (layer2)                    [32, 256, 56, 56]         [32, 512, 28, 28]         --                        False\n","│    └─Bottleneck (0)                    [32, 256, 56, 56]         [32, 512, 28, 28]         --                        False\n","│    │    └─Conv2d (conv1)               [32, 256, 56, 56]         [32, 128, 56, 56]         (32,768)                  False\n","│    │    └─BatchNorm2d (bn1)            [32, 128, 56, 56]         [32, 128, 56, 56]         (256)                     False\n","│    │    └─ReLU (relu)                  [32, 128, 56, 56]         [32, 128, 56, 56]         --                        --\n","│    │    └─Conv2d (conv2)               [32, 128, 56, 56]         [32, 128, 28, 28]         (147,456)                 False\n","│    │    └─BatchNorm2d (bn2)            [32, 128, 28, 28]         [32, 128, 28, 28]         (256)                     False\n","│    │    └─ReLU (relu)                  [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n","│    │    └─Conv2d (conv3)               [32, 128, 28, 28]         [32, 512, 28, 28]         (65,536)                  False\n","│    │    └─BatchNorm2d (bn3)            [32, 512, 28, 28]         [32, 512, 28, 28]         (1,024)                   False\n","│    │    └─Sequential (downsample)      [32, 256, 56, 56]         [32, 512, 28, 28]         (132,096)                 False\n","│    │    └─ReLU (relu)                  [32, 512, 28, 28]         [32, 512, 28, 28]         --                        --\n","│    └─Bottleneck (1)                    [32, 512, 28, 28]         [32, 512, 28, 28]         --                        False\n","│    │    └─Conv2d (conv1)               [32, 512, 28, 28]         [32, 128, 28, 28]         (65,536)                  False\n","│    │    └─BatchNorm2d (bn1)            [32, 128, 28, 28]         [32, 128, 28, 28]         (256)                     False\n","│    │    └─ReLU (relu)                  [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n","│    │    └─Conv2d (conv2)               [32, 128, 28, 28]         [32, 128, 28, 28]         (147,456)                 False\n","│    │    └─BatchNorm2d (bn2)            [32, 128, 28, 28]         [32, 128, 28, 28]         (256)                     False\n","│    │    └─ReLU (relu)                  [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n","│    │    └─Conv2d (conv3)               [32, 128, 28, 28]         [32, 512, 28, 28]         (65,536)                  False\n","│    │    └─BatchNorm2d (bn3)            [32, 512, 28, 28]         [32, 512, 28, 28]         (1,024)                   False\n","│    │    └─ReLU (relu)                  [32, 512, 28, 28]         [32, 512, 28, 28]         --                        --\n","│    └─Bottleneck (2)                    [32, 512, 28, 28]         [32, 512, 28, 28]         --                        False\n","│    │    └─Conv2d (conv1)               [32, 512, 28, 28]         [32, 128, 28, 28]         (65,536)                  False\n","│    │    └─BatchNorm2d (bn1)            [32, 128, 28, 28]         [32, 128, 28, 28]         (256)                     False\n","│    │    └─ReLU (relu)                  [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n","│    │    └─Conv2d (conv2)               [32, 128, 28, 28]         [32, 128, 28, 28]         (147,456)                 False\n","│    │    └─BatchNorm2d (bn2)            [32, 128, 28, 28]         [32, 128, 28, 28]         (256)                     False\n","│    │    └─ReLU (relu)                  [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n","│    │    └─Conv2d (conv3)               [32, 128, 28, 28]         [32, 512, 28, 28]         (65,536)                  False\n","│    │    └─BatchNorm2d (bn3)            [32, 512, 28, 28]         [32, 512, 28, 28]         (1,024)                   False\n","│    │    └─ReLU (relu)                  [32, 512, 28, 28]         [32, 512, 28, 28]         --                        --\n","│    └─Bottleneck (3)                    [32, 512, 28, 28]         [32, 512, 28, 28]         --                        False\n","│    │    └─Conv2d (conv1)               [32, 512, 28, 28]         [32, 128, 28, 28]         (65,536)                  False\n","│    │    └─BatchNorm2d (bn1)            [32, 128, 28, 28]         [32, 128, 28, 28]         (256)                     False\n","│    │    └─ReLU (relu)                  [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n","│    │    └─Conv2d (conv2)               [32, 128, 28, 28]         [32, 128, 28, 28]         (147,456)                 False\n","│    │    └─BatchNorm2d (bn2)            [32, 128, 28, 28]         [32, 128, 28, 28]         (256)                     False\n","│    │    └─ReLU (relu)                  [32, 128, 28, 28]         [32, 128, 28, 28]         --                        --\n","│    │    └─Conv2d (conv3)               [32, 128, 28, 28]         [32, 512, 28, 28]         (65,536)                  False\n","│    │    └─BatchNorm2d (bn3)            [32, 512, 28, 28]         [32, 512, 28, 28]         (1,024)                   False\n","│    │    └─ReLU (relu)                  [32, 512, 28, 28]         [32, 512, 28, 28]         --                        --\n","├─Sequential (layer3)                    [32, 512, 28, 28]         [32, 1024, 14, 14]        --                        False\n","│    └─Bottleneck (0)                    [32, 512, 28, 28]         [32, 1024, 14, 14]        --                        False\n","│    │    └─Conv2d (conv1)               [32, 512, 28, 28]         [32, 256, 28, 28]         (131,072)                 False\n","│    │    └─BatchNorm2d (bn1)            [32, 256, 28, 28]         [32, 256, 28, 28]         (512)                     False\n","│    │    └─ReLU (relu)                  [32, 256, 28, 28]         [32, 256, 28, 28]         --                        --\n","│    │    └─Conv2d (conv2)               [32, 256, 28, 28]         [32, 256, 14, 14]         (589,824)                 False\n","│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","│    │    └─ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","│    │    └─Conv2d (conv3)               [32, 256, 14, 14]         [32, 1024, 14, 14]        (262,144)                 False\n","│    │    └─BatchNorm2d (bn3)            [32, 1024, 14, 14]        [32, 1024, 14, 14]        (2,048)                   False\n","│    │    └─Sequential (downsample)      [32, 512, 28, 28]         [32, 1024, 14, 14]        (526,336)                 False\n","│    │    └─ReLU (relu)                  [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        --\n","│    └─Bottleneck (1)                    [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        False\n","│    │    └─Conv2d (conv1)               [32, 1024, 14, 14]        [32, 256, 14, 14]         (262,144)                 False\n","│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","│    │    └─ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","│    │    └─Conv2d (conv2)               [32, 256, 14, 14]         [32, 256, 14, 14]         (589,824)                 False\n","│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","│    │    └─ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","│    │    └─Conv2d (conv3)               [32, 256, 14, 14]         [32, 1024, 14, 14]        (262,144)                 False\n","│    │    └─BatchNorm2d (bn3)            [32, 1024, 14, 14]        [32, 1024, 14, 14]        (2,048)                   False\n","│    │    └─ReLU (relu)                  [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        --\n","│    └─Bottleneck (2)                    [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        False\n","│    │    └─Conv2d (conv1)               [32, 1024, 14, 14]        [32, 256, 14, 14]         (262,144)                 False\n","│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","│    │    └─ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","│    │    └─Conv2d (conv2)               [32, 256, 14, 14]         [32, 256, 14, 14]         (589,824)                 False\n","│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","│    │    └─ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","│    │    └─Conv2d (conv3)               [32, 256, 14, 14]         [32, 1024, 14, 14]        (262,144)                 False\n","│    │    └─BatchNorm2d (bn3)            [32, 1024, 14, 14]        [32, 1024, 14, 14]        (2,048)                   False\n","│    │    └─ReLU (relu)                  [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        --\n","│    └─Bottleneck (3)                    [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        False\n","│    │    └─Conv2d (conv1)               [32, 1024, 14, 14]        [32, 256, 14, 14]         (262,144)                 False\n","│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","│    │    └─ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","│    │    └─Conv2d (conv2)               [32, 256, 14, 14]         [32, 256, 14, 14]         (589,824)                 False\n","│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","│    │    └─ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","│    │    └─Conv2d (conv3)               [32, 256, 14, 14]         [32, 1024, 14, 14]        (262,144)                 False\n","│    │    └─BatchNorm2d (bn3)            [32, 1024, 14, 14]        [32, 1024, 14, 14]        (2,048)                   False\n","│    │    └─ReLU (relu)                  [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        --\n","│    └─Bottleneck (4)                    [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        False\n","│    │    └─Conv2d (conv1)               [32, 1024, 14, 14]        [32, 256, 14, 14]         (262,144)                 False\n","│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","│    │    └─ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","│    │    └─Conv2d (conv2)               [32, 256, 14, 14]         [32, 256, 14, 14]         (589,824)                 False\n","│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","│    │    └─ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","│    │    └─Conv2d (conv3)               [32, 256, 14, 14]         [32, 1024, 14, 14]        (262,144)                 False\n","│    │    └─BatchNorm2d (bn3)            [32, 1024, 14, 14]        [32, 1024, 14, 14]        (2,048)                   False\n","│    │    └─ReLU (relu)                  [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        --\n","│    └─Bottleneck (5)                    [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        False\n","│    │    └─Conv2d (conv1)               [32, 1024, 14, 14]        [32, 256, 14, 14]         (262,144)                 False\n","│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","│    │    └─ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","│    │    └─Conv2d (conv2)               [32, 256, 14, 14]         [32, 256, 14, 14]         (589,824)                 False\n","│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]         [32, 256, 14, 14]         (512)                     False\n","│    │    └─ReLU (relu)                  [32, 256, 14, 14]         [32, 256, 14, 14]         --                        --\n","│    │    └─Conv2d (conv3)               [32, 256, 14, 14]         [32, 1024, 14, 14]        (262,144)                 False\n","│    │    └─BatchNorm2d (bn3)            [32, 1024, 14, 14]        [32, 1024, 14, 14]        (2,048)                   False\n","│    │    └─ReLU (relu)                  [32, 1024, 14, 14]        [32, 1024, 14, 14]        --                        --\n","├─Sequential (layer4)                    [32, 1024, 14, 14]        [32, 2048, 7, 7]          --                        False\n","│    └─Bottleneck (0)                    [32, 1024, 14, 14]        [32, 2048, 7, 7]          --                        False\n","│    │    └─Conv2d (conv1)               [32, 1024, 14, 14]        [32, 512, 14, 14]         (524,288)                 False\n","│    │    └─BatchNorm2d (bn1)            [32, 512, 14, 14]         [32, 512, 14, 14]         (1,024)                   False\n","│    │    └─ReLU (relu)                  [32, 512, 14, 14]         [32, 512, 14, 14]         --                        --\n","│    │    └─Conv2d (conv2)               [32, 512, 14, 14]         [32, 512, 7, 7]           (2,359,296)               False\n","│    │    └─BatchNorm2d (bn2)            [32, 512, 7, 7]           [32, 512, 7, 7]           (1,024)                   False\n","│    │    └─ReLU (relu)                  [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n","│    │    └─Conv2d (conv3)               [32, 512, 7, 7]           [32, 2048, 7, 7]          (1,048,576)               False\n","│    │    └─BatchNorm2d (bn3)            [32, 2048, 7, 7]          [32, 2048, 7, 7]          (4,096)                   False\n","│    │    └─Sequential (downsample)      [32, 1024, 14, 14]        [32, 2048, 7, 7]          (2,101,248)               False\n","│    │    └─ReLU (relu)                  [32, 2048, 7, 7]          [32, 2048, 7, 7]          --                        --\n","│    └─Bottleneck (1)                    [32, 2048, 7, 7]          [32, 2048, 7, 7]          --                        False\n","│    │    └─Conv2d (conv1)               [32, 2048, 7, 7]          [32, 512, 7, 7]           (1,048,576)               False\n","│    │    └─BatchNorm2d (bn1)            [32, 512, 7, 7]           [32, 512, 7, 7]           (1,024)                   False\n","│    │    └─ReLU (relu)                  [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n","│    │    └─Conv2d (conv2)               [32, 512, 7, 7]           [32, 512, 7, 7]           (2,359,296)               False\n","│    │    └─BatchNorm2d (bn2)            [32, 512, 7, 7]           [32, 512, 7, 7]           (1,024)                   False\n","│    │    └─ReLU (relu)                  [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n","│    │    └─Conv2d (conv3)               [32, 512, 7, 7]           [32, 2048, 7, 7]          (1,048,576)               False\n","│    │    └─BatchNorm2d (bn3)            [32, 2048, 7, 7]          [32, 2048, 7, 7]          (4,096)                   False\n","│    │    └─ReLU (relu)                  [32, 2048, 7, 7]          [32, 2048, 7, 7]          --                        --\n","│    └─Bottleneck (2)                    [32, 2048, 7, 7]          [32, 2048, 7, 7]          --                        False\n","│    │    └─Conv2d (conv1)               [32, 2048, 7, 7]          [32, 512, 7, 7]           (1,048,576)               False\n","│    │    └─BatchNorm2d (bn1)            [32, 512, 7, 7]           [32, 512, 7, 7]           (1,024)                   False\n","│    │    └─ReLU (relu)                  [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n","│    │    └─Conv2d (conv2)               [32, 512, 7, 7]           [32, 512, 7, 7]           (2,359,296)               False\n","│    │    └─BatchNorm2d (bn2)            [32, 512, 7, 7]           [32, 512, 7, 7]           (1,024)                   False\n","│    │    └─ReLU (relu)                  [32, 512, 7, 7]           [32, 512, 7, 7]           --                        --\n","│    │    └─Conv2d (conv3)               [32, 512, 7, 7]           [32, 2048, 7, 7]          (1,048,576)               False\n","│    │    └─BatchNorm2d (bn3)            [32, 2048, 7, 7]          [32, 2048, 7, 7]          (4,096)                   False\n","│    │    └─ReLU (relu)                  [32, 2048, 7, 7]          [32, 2048, 7, 7]          --                        --\n","├─AdaptiveAvgPool2d (avgpool)            [32, 2048, 7, 7]          [32, 2048, 1, 1]          --                        --\n","├─Sequential (fc)                        [32, 2048]                [32, 36]                  --                        True\n","│    └─Dropout (0)                       [32, 2048]                [32, 2048]                --                        --\n","│    └─Linear (1)                        [32, 2048]                [32, 36]                  73,764                    True\n","============================================================================================================================================\n","Total params: 23,581,796\n","Trainable params: 73,764\n","Non-trainable params: 23,508,032\n","Total mult-adds (Units.GIGABYTES): 130.79\n","============================================================================================================================================\n","Input size (MB): 19.27\n","Forward/backward pass size (MB): 5690.37\n","Params size (MB): 94.33\n","Estimated Total Size (MB): 5803.96\n","============================================================================================================================================"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["## 06 Training"],"metadata":{"id":"GTb6cKqF83it"}},{"cell_type":"code","source":["def train_step(model: torch.nn.Module,\n","               dataloader: torch.utils.data.DataLoader,\n","               loss_fn: torch.nn.Module,\n","               optimizer: torch.optim.Optimizer,\n","               device: torch.device) -> Tuple[float, float]:\n","    \"\"\"\n","    단일 학습 스텝을 수행하는 함수\n","    \"\"\"\n","    model.train()  # 학습 모드 설정\n","    train_loss, train_acc = 0, 0  # 학습 손실 및 정확도 초기화\n","\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)  # 입력 데이터와 라벨을 지정된 장치로 이동\n","        optimizer.zero_grad()  # 이전 단계의 그래디언트 초기화\n","        y_pred = model(X)  # 모델 예측 수행\n","        loss = loss_fn(y_pred, y)  # 손실 계산\n","        loss.backward()  # 역전파(Backpropagation)\n","        optimizer.step()  # 가중치 업데이트\n","\n","        train_loss += loss.item()  # 손실 합산\n","        acc = (y_pred.argmax(dim=1) == y).sum().item() / len(y)  # 정확도 계산\n","        train_acc += acc  # 정확도 합산\n","\n","    return train_loss / len(dataloader), train_acc / len(dataloader)  # 평균 손실 및 정확도 반환\n","\n","\n","def eval_step(model: torch.nn.Module,\n","              dataloader: torch.utils.data.DataLoader,\n","              loss_fn: torch.nn.Module,\n","              device: torch.device) -> Tuple[float, float]:\n","    \"\"\"\n","    단일 평가 스텝을 수행하는 함수\n","    \"\"\"\n","    model.eval()  # 평가 모드 설정\n","    eval_loss, eval_acc = 0, 0  # 평가 손실 및 정확도 초기화\n","\n","    with torch.inference_mode():  # 평가 시 그래디언트 계산 비활성화 (속도 향상)\n","        for batch, (X, y) in enumerate(dataloader):\n","            X, y = X.to(device), y.to(device)  # 입력 데이터와 라벨을 지정된 장치로 이동\n","            y_pred = model(X)  # 모델 예측 수행\n","            loss = loss_fn(y_pred, y)  # 손실 계산\n","            eval_loss += loss.item()  # 손실 합산\n","            acc = (y_pred.argmax(dim=1) == y).sum().item() / len(y)  # 정확도 계산\n","            eval_acc += acc  # 정확도 합산\n","\n","    return eval_loss / len(dataloader), eval_acc / len(dataloader)  # 평균 손실 및 정확도 반환\n","\n","\n","def train_eval(model: torch.nn.Module,\n","               train_dataloader: torch.utils.data.DataLoader,\n","               val_dataloader: torch.utils.data.DataLoader,\n","               epochs: int,\n","               loss_fn: torch.nn.Module,\n","               optimizer: torch.optim.Optimizer,\n","               device: torch.device) -> List[Dict[str, float]]:\n","    \"\"\"\n","    지정된 에포크(epochs) 동안 모델을 학습하고 평가하는 함수\n","    \"\"\"\n","    results = []  # 학습 및 평가 결과를 저장할 리스트\n","\n","    # 전체 학습 시작 시간 기록\n","    total_start_time = time.time()\n","\n","    for epoch in range(epochs):\n","        # 학습 단계 수행\n","        train_loss, train_acc = train_step(model, train_dataloader, loss_fn, optimizer, device)\n","        # 평가 단계 수행\n","        val_loss, val_acc = eval_step(model, val_dataloader, loss_fn, device)\n","\n","        # 현재 학습률 확인\n","        current_lr = optimizer.param_groups[0]['lr']\n","\n","        # 학습 및 평가 결과 출력\n","        print(f\"Epoch {epoch+1}/{epochs}: \\n\"\n","              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} \\n\"\n","              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | LR: {current_lr:.6f}\")\n","\n","        # 결과 저장\n","        results.append({\n","            \"epoch\": epoch+1,\n","            \"Train_loss\": train_loss,\n","            \"Train_acc\": train_acc,\n","            \"Val_loss\": val_loss,\n","            \"Val_acc\": val_acc,\n","            \"lr\": current_lr\n","        })\n","\n","    # 전체 학습 끝 시간 기록\n","    total_end_time = time.time()\n","    total_minutes = (total_end_time - total_start_time) / 60\n","\n","    print(f\"\\n🕒 전체 학습 시간: {total_minutes:.2f}분\")\n","\n","    return results"],"metadata":{"id":"H--aT8R1866W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### train()"],"metadata":{"id":"dp0Ex7zKBKrS"}},{"cell_type":"code","source":["# 손실 함수 및 옵티마이저 초기화\n","loss_fn = nn.CrossEntropyLoss()  # 다중 분류 문제에 적합한 크로스 엔트로피 손실 함수 사용\n","optimizer = optim.Adam(params=ResNet_model.parameters(), lr=0.001, weight_decay=0.0001)  # Adam 옵티마이저 사용, 학습률(lr) 설정\n","\n","# 학습할 총 에포크 수 설정\n","NUM_EPOCHS = 50\n","\n","# 학습 실행\n","results = train_eval(model=ResNet_model,\n","                     train_dataloader=train_dataloader,\n","                     val_dataloader=validation_dataloader,\n","                     epochs=NUM_EPOCHS,\n","                     loss_fn=loss_fn,\n","                     optimizer=optimizer,\n","                     device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4WB-cTuvVyNY","outputId":"75c89973-14cb-4d58-a19b-05baaeb580fc","executionInfo":{"status":"ok","timestamp":1743313871030,"user_tz":-540,"elapsed":2826231,"user":{"displayName":"이수인","userId":"16249151905029041959"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50: \n","Train Loss: 1.8686 | Train Acc: 0.6470 \n","Val Loss: 0.7285 | Val Acc: 0.8889 | LR: 0.001000\n","Epoch 2/50: \n","Train Loss: 0.7845 | Train Acc: 0.8430 \n","Val Loss: 0.4207 | Val Acc: 0.9289 | LR: 0.001000\n","Epoch 3/50: \n","Train Loss: 0.5523 | Train Acc: 0.8772 \n","Val Loss: 0.3141 | Val Acc: 0.9332 | LR: 0.001000\n","Epoch 4/50: \n","Train Loss: 0.4446 | Train Acc: 0.9015 \n","Val Loss: 0.2666 | Val Acc: 0.9304 | LR: 0.001000\n","Epoch 5/50: \n","Train Loss: 0.3670 | Train Acc: 0.9174 \n","Val Loss: 0.2277 | Val Acc: 0.9529 | LR: 0.001000\n","Epoch 6/50: \n","Train Loss: 0.3196 | Train Acc: 0.9269 \n","Val Loss: 0.2110 | Val Acc: 0.9444 | LR: 0.001000\n","Epoch 7/50: \n","Train Loss: 0.2955 | Train Acc: 0.9277 \n","Val Loss: 0.1860 | Val Acc: 0.9616 | LR: 0.001000\n","Epoch 8/50: \n","Train Loss: 0.2641 | Train Acc: 0.9377 \n","Val Loss: 0.1784 | Val Acc: 0.9574 | LR: 0.001000\n","Epoch 9/50: \n","Train Loss: 0.2390 | Train Acc: 0.9481 \n","Val Loss: 0.1850 | Val Acc: 0.9445 | LR: 0.001000\n","Epoch 10/50: \n","Train Loss: 0.2231 | Train Acc: 0.9474 \n","Val Loss: 0.1629 | Val Acc: 0.9574 | LR: 0.001000\n","Epoch 11/50: \n","Train Loss: 0.2082 | Train Acc: 0.9463 \n","Val Loss: 0.1591 | Val Acc: 0.9545 | LR: 0.001000\n","Epoch 12/50: \n","Train Loss: 0.1897 | Train Acc: 0.9559 \n","Val Loss: 0.1619 | Val Acc: 0.9488 | LR: 0.001000\n","Epoch 13/50: \n","Train Loss: 0.1903 | Train Acc: 0.9519 \n","Val Loss: 0.1562 | Val Acc: 0.9503 | LR: 0.001000\n","Epoch 14/50: \n","Train Loss: 0.1744 | Train Acc: 0.9551 \n","Val Loss: 0.1587 | Val Acc: 0.9560 | LR: 0.001000\n","Epoch 15/50: \n","Train Loss: 0.1696 | Train Acc: 0.9551 \n","Val Loss: 0.1670 | Val Acc: 0.9545 | LR: 0.001000\n","Epoch 16/50: \n","Train Loss: 0.1631 | Train Acc: 0.9614 \n","Val Loss: 0.1572 | Val Acc: 0.9560 | LR: 0.001000\n","Epoch 17/50: \n","Train Loss: 0.1554 | Train Acc: 0.9629 \n","Val Loss: 0.1666 | Val Acc: 0.9488 | LR: 0.001000\n","Epoch 18/50: \n","Train Loss: 0.1524 | Train Acc: 0.9635 \n","Val Loss: 0.1473 | Val Acc: 0.9574 | LR: 0.001000\n","Epoch 19/50: \n","Train Loss: 0.1458 | Train Acc: 0.9648 \n","Val Loss: 0.1479 | Val Acc: 0.9574 | LR: 0.001000\n","Epoch 20/50: \n","Train Loss: 0.1423 | Train Acc: 0.9639 \n","Val Loss: 0.1476 | Val Acc: 0.9631 | LR: 0.001000\n","Epoch 21/50: \n","Train Loss: 0.1369 | Train Acc: 0.9668 \n","Val Loss: 0.1409 | Val Acc: 0.9616 | LR: 0.001000\n","Epoch 22/50: \n","Train Loss: 0.1319 | Train Acc: 0.9649 \n","Val Loss: 0.1417 | Val Acc: 0.9574 | LR: 0.001000\n","Epoch 23/50: \n","Train Loss: 0.1308 | Train Acc: 0.9676 \n","Val Loss: 0.1377 | Val Acc: 0.9616 | LR: 0.001000\n","Epoch 24/50: \n","Train Loss: 0.1307 | Train Acc: 0.9672 \n","Val Loss: 0.1236 | Val Acc: 0.9616 | LR: 0.001000\n","Epoch 25/50: \n","Train Loss: 0.1309 | Train Acc: 0.9655 \n","Val Loss: 0.1366 | Val Acc: 0.9659 | LR: 0.001000\n","Epoch 26/50: \n","Train Loss: 0.1293 | Train Acc: 0.9647 \n","Val Loss: 0.1488 | Val Acc: 0.9588 | LR: 0.001000\n","Epoch 27/50: \n","Train Loss: 0.1206 | Train Acc: 0.9683 \n","Val Loss: 0.1352 | Val Acc: 0.9602 | LR: 0.001000\n","Epoch 28/50: \n","Train Loss: 0.1212 | Train Acc: 0.9682 \n","Val Loss: 0.1425 | Val Acc: 0.9631 | LR: 0.001000\n","Epoch 29/50: \n","Train Loss: 0.1093 | Train Acc: 0.9744 \n","Val Loss: 0.1472 | Val Acc: 0.9545 | LR: 0.001000\n","Epoch 30/50: \n","Train Loss: 0.1185 | Train Acc: 0.9660 \n","Val Loss: 0.1440 | Val Acc: 0.9659 | LR: 0.001000\n","Epoch 31/50: \n","Train Loss: 0.1133 | Train Acc: 0.9717 \n","Val Loss: 0.1248 | Val Acc: 0.9631 | LR: 0.001000\n","Epoch 32/50: \n","Train Loss: 0.1144 | Train Acc: 0.9680 \n","Val Loss: 0.1398 | Val Acc: 0.9644 | LR: 0.001000\n","Epoch 33/50: \n","Train Loss: 0.1162 | Train Acc: 0.9677 \n","Val Loss: 0.1296 | Val Acc: 0.9560 | LR: 0.001000\n","Epoch 34/50: \n","Train Loss: 0.1137 | Train Acc: 0.9716 \n","Val Loss: 0.1332 | Val Acc: 0.9631 | LR: 0.001000\n","Epoch 35/50: \n","Train Loss: 0.1141 | Train Acc: 0.9661 \n","Val Loss: 0.1323 | Val Acc: 0.9659 | LR: 0.001000\n","Epoch 36/50: \n","Train Loss: 0.1109 | Train Acc: 0.9723 \n","Val Loss: 0.1310 | Val Acc: 0.9588 | LR: 0.001000\n","Epoch 37/50: \n","Train Loss: 0.1067 | Train Acc: 0.9737 \n","Val Loss: 0.1275 | Val Acc: 0.9631 | LR: 0.001000\n","Epoch 38/50: \n","Train Loss: 0.1073 | Train Acc: 0.9713 \n","Val Loss: 0.1299 | Val Acc: 0.9602 | LR: 0.001000\n","Epoch 39/50: \n","Train Loss: 0.1029 | Train Acc: 0.9725 \n","Val Loss: 0.1312 | Val Acc: 0.9702 | LR: 0.001000\n","Epoch 40/50: \n","Train Loss: 0.1067 | Train Acc: 0.9700 \n","Val Loss: 0.1310 | Val Acc: 0.9688 | LR: 0.001000\n","Epoch 41/50: \n","Train Loss: 0.1128 | Train Acc: 0.9673 \n","Val Loss: 0.1292 | Val Acc: 0.9645 | LR: 0.001000\n","Epoch 42/50: \n","Train Loss: 0.1055 | Train Acc: 0.9697 \n","Val Loss: 0.1343 | Val Acc: 0.9645 | LR: 0.001000\n","Epoch 43/50: \n","Train Loss: 0.1001 | Train Acc: 0.9764 \n","Val Loss: 0.1281 | Val Acc: 0.9644 | LR: 0.001000\n","Epoch 44/50: \n","Train Loss: 0.0989 | Train Acc: 0.9728 \n","Val Loss: 0.1178 | Val Acc: 0.9645 | LR: 0.001000\n","Epoch 45/50: \n","Train Loss: 0.1029 | Train Acc: 0.9719 \n","Val Loss: 0.1185 | Val Acc: 0.9602 | LR: 0.001000\n","Epoch 46/50: \n","Train Loss: 0.1031 | Train Acc: 0.9694 \n","Val Loss: 0.1284 | Val Acc: 0.9631 | LR: 0.001000\n","Epoch 47/50: \n","Train Loss: 0.1011 | Train Acc: 0.9726 \n","Val Loss: 0.1336 | Val Acc: 0.9588 | LR: 0.001000\n","Epoch 48/50: \n","Train Loss: 0.1076 | Train Acc: 0.9689 \n","Val Loss: 0.1246 | Val Acc: 0.9645 | LR: 0.001000\n","Epoch 49/50: \n","Train Loss: 0.0994 | Train Acc: 0.9744 \n","Val Loss: 0.1243 | Val Acc: 0.9688 | LR: 0.001000\n","Epoch 50/50: \n","Train Loss: 0.1105 | Train Acc: 0.9697 \n","Val Loss: 0.1232 | Val Acc: 0.9645 | LR: 0.001000\n","\n","🕒 전체 학습 시간: 47.10분\n"]}]},{"cell_type":"markdown","source":["## 07 Result"],"metadata":{"id":"nizwunc-T_he"}},{"cell_type":"code","source":["# 결과를 데이터프레임으로 변환\n","results_df = pd.DataFrame(results)"],"metadata":{"id":"WGNESaqNKDgv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 테스트 셋 평가\n","test_loss, test_acc = eval_step(model=ResNet_model,\n","                                dataloader=test_dataloader,\n","                                loss_fn=loss_fn,\n","                                device=device)"],"metadata":{"id":"F1_84555J13C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 결과\n","print(f\"Test accuracy: {test_acc:.6f}\")\n","print(f\"Test Loss: {test_loss:.6f}\")"],"metadata":{"id":"cbyA64udJ3JD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743313896569,"user_tz":-540,"elapsed":20,"user":{"displayName":"이수인","userId":"16249151905029041959"}},"outputId":"ed8075b3-8e86-4732-ca5b-dc841bf96a2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy: 0.968750\n","Test Loss: 0.104553\n"]}]},{"cell_type":"code","source":["# Test accuracy: 0.971354\n","# Test Loss: 0.098235"],"metadata":{"id":"VbGLdQ7zHutr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 08 DB 저장"],"metadata":{"id":"_lLjAY5N7d5k"}},{"cell_type":"code","source":["from sqlalchemy import create_engine\n","\n","# DB 연결 정보 입력 (Aiven MySQL 기준)\n","host = 'YOUR_AIVEN_HOST'\n","port = 'YOUR_AIVEN_PORT'\n","username = 'YOUR_USERNAME'\n","password = 'YOUR_PASSWORD'\n","database = 'YOUR_DATABASE'\n","\n","# SQLAlchemy 엔진 생성\n","engine = create_engine(f\"mysql+pymysql://{username}:{password}@{host}:{port}/{database}\")\n","# DataFrame을 MySQL에 저장\n","results_df.to_sql(name='train_logs_resnet', con=engine, if_exists='append', index=False)\n","\n","# 테스트 결과를 DataFrame으로 변환\n","test_result_df = pd.DataFrame([{\n","    \"model_name\": \"ResNet50\",\n","    \"test_loss\": test_loss,\n","    \"test_acc\": test_acc\n","}])\n","\n","test_result_df.to_sql(name='test_results', con=engine, if_exists='append', index=False)"],"metadata":{"id":"49bcl37v7fir","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743313897578,"user_tz":-540,"elapsed":1007,"user":{"displayName":"이수인","userId":"16249151905029041959"}},"outputId":"b2be6972-d035-41e6-fdc0-ce78c0b579fb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":15}]}]}