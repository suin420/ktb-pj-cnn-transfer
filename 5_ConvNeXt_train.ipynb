{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsUk7PvBnt7q"
   },
   "source": [
    "## 00 Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0RSLLBJc22tE"
   },
   "outputs": [],
   "source": [
    "# !pip install torchinfo\n",
    "# !pip install modules\n",
    "# !pip install pymysql sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfjalG9B24DQ"
   },
   "source": [
    "## 01 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sedXL5wU28a8"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from collections import OrderedDict # emaì—ì„œ ì‚¬ìš©\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchinfo import summary\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "es5nnCzExTJ7"
   },
   "source": [
    "## 02 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2iirxuwWUYku"
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„° ê²½ë¡œ ì„¤ì •\n",
    "data_dir = 'your_path/fruit-and-vegetable-image'\n",
    "\n",
    "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "train_filepaths = list(Path(train_dir).rglob('*.jpg')) + \\\n",
    "                  list(Path(train_dir).rglob('*.jpeg')) + \\\n",
    "                  list(Path(train_dir).rglob('*.png')) + \\\n",
    "                  list(Path(train_dir).rglob('*.JPG'))\n",
    "\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "test_filepaths = list(Path(test_dir).rglob('*.jpg')) + \\\n",
    "                 list(Path(test_dir).rglob('*.jpeg')) + \\\n",
    "                 list(Path(test_dir).rglob('*.png')) + \\\n",
    "                 list(Path(test_dir).rglob('*.JPG'))\n",
    "\n",
    "val_dir = os.path.join(data_dir, 'validation')\n",
    "val_filepaths = list(Path(val_dir).rglob('*.jpg')) + \\\n",
    "                 list(Path(val_dir).rglob('*.jpeg')) + \\\n",
    "                 list(Path(val_dir).rglob('*.png')) + \\\n",
    "                 list(Path(val_dir).rglob('*.JPG'))\n",
    "\n",
    "\n",
    "def proc_img(filepath):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ íŒŒì¼ì˜ ê²½ë¡œì™€ ë¼ë²¨ì„ í¬í•¨í•˜ëŠ” DataFrameì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "\n",
    "    # íŒŒì¼ ê²½ë¡œì—ì„œ ë¼ë²¨(í´ë”ëª…) ì¶”ì¶œ\n",
    "    labels = [str(filepath[i]).split(\"/\")[-2] for i in range(len(filepath))]\n",
    "\n",
    "    # íŒŒì¼ ê²½ë¡œë¥¼ pandas Seriesë¡œ ë³€í™˜í•˜ê³  ë¬¸ìì—´ë¡œ ì €ì¥\n",
    "    filepath = pd.Series(filepath, name='Filepath').astype(str)\n",
    "\n",
    "    # ë¼ë²¨ì„ pandas Seriesë¡œ ë³€í™˜\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    # íŒŒì¼ ê²½ë¡œì™€ ë¼ë²¨ì„ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ í•©ì¹˜ê¸°\n",
    "    df = pd.concat([filepath, labels], axis=1)\n",
    "\n",
    "    # ë°ì´í„° í”„ë ˆì„ì„ ëœë¤í•˜ê²Œ ì„ê³  ì¸ë±ìŠ¤ ì´ˆê¸°í™”\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# í•™ìŠµ(train), í…ŒìŠ¤íŠ¸(test), ê²€ì¦(validation) ë°ì´í„° í”„ë ˆì„ ìƒì„±\n",
    "train_df = proc_img(train_filepaths)\n",
    "test_df = proc_img(test_filepaths)\n",
    "val_df = proc_img(val_filepaths)\n",
    "\n",
    "# í´ë˜ìŠ¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "class_labels = train_df.Label.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWap5H_13nm1"
   },
   "source": [
    "## 03 Create Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1743317171761,
     "user": {
      "displayName": "ì´ìˆ˜ì¸",
      "userId": "16249151905029041959"
     },
     "user_tz": -540
    },
    "id": "024RhS9w2csY",
    "outputId": "4479313e-83cf-47a2-aeb9-4f9e33474fc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[232]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BILINEAR\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ConvNeXt ëª¨ë¸ì˜ ê¸°ë³¸ ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "ConvNeXt_weights = models.ConvNeXt_Base_Weights.DEFAULT\n",
    "\n",
    "# í•´ë‹¹ ê°€ì¤‘ì¹˜ì— ë§ëŠ” ë³€í™˜(transform) ê°ì²´ ê°€ì ¸ì˜¤ê¸°\n",
    "ConvNeXt_transformer = ConvNeXt_weights.transforms() # ëª¨ë¸ì´ ìš”êµ¬í•˜ëŠ” ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì´ ë°˜í™˜\n",
    "\n",
    "# ë³€í™˜ ê°ì²´ ì¶œë ¥ (ì–´ë–¤ ë³€í™˜ì´ ì ìš©ë˜ëŠ”ì§€ í™•ì¸)\n",
    "ConvNeXt_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1743317171870,
     "user": {
      "displayName": "ì´ìˆ˜ì¸",
      "userId": "16249151905029041959"
     },
     "user_tz": -540
    },
    "id": "XBf_Bwysucgu",
    "outputId": "6fa3c8c4-74ce-4997-c7b3-becad499598c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 3115\n",
      "Augmented dataset size: 3115\n",
      "Combined dataset size: 6230\n",
      "Validation dataset szie: 702\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 3115\n",
      "    Root location: /content/drive/MyDrive/Colab_Notebooks/fruit-and-vegetable-image/train\n",
      "    StandardTransform\n",
      "Transform: ImageClassification(\n",
      "               crop_size=[224]\n",
      "               resize_size=[232]\n",
      "               mean=[0.485, 0.456, 0.406]\n",
      "               std=[0.229, 0.224, 0.225]\n",
      "               interpolation=InterpolationMode.BILINEAR\n",
      "           ) \n",
      "\n",
      " Dataset ImageFolder\n",
      "    Number of datapoints: 3115\n",
      "    Root location: /content/drive/MyDrive/Colab_Notebooks/fruit-and-vegetable-image/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomRotation(degrees=[-20.0, 20.0], interpolation=nearest, expand=False, fill=0)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               Lambda()\n",
      "               ImageClassification(\n",
      "               crop_size=[224]\n",
      "               resize_size=[232]\n",
      "               mean=[0.485, 0.456, 0.406]\n",
      "               std=[0.229, 0.224, 0.225]\n",
      "               interpolation=InterpolationMode.BILINEAR\n",
      "           )\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# ëœë¤í•œ ì‚¬ê°í˜• ë…¸ì´ì¦ˆ ì¶”ê°€ í•¨ìˆ˜\n",
    "def add_rectangle_noise(image):\n",
    "    \"\"\"ì´ë¯¸ì§€ì— ëœë¤í•œ í¬ê¸°ì™€ ìœ„ì¹˜ì˜ ì‚¬ê°í˜• ë…¸ì´ì¦ˆ ì¶”ê°€\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    width, height = image.size\n",
    "\n",
    "    # ë…¸ì´ì¦ˆ í¬ê¸° (ì „ì²´ ì´ë¯¸ì§€ í¬ê¸°ì˜ 30~50%)\n",
    "    box_width = random.randint(int(0.3 * width), int(0.5 * width))\n",
    "    box_height = random.randint(int(0.3 * height), int(0.5 * height))\n",
    "\n",
    "    # ëœë¤ ìœ„ì¹˜\n",
    "    x1 = random.randint(0, width - box_width)\n",
    "    y1 = random.randint(0, height - box_height)\n",
    "    x2 = x1 + box_width\n",
    "    y2 = y1 + box_height\n",
    "\n",
    "    # ëœë¤ ìƒ‰ìƒ (0~255 ë²”ìœ„)\n",
    "    noise_color = tuple(np.random.randint(0, 256, size=3).tolist())\n",
    "\n",
    "    # ì‚¬ê°í˜• ê·¸ë¦¬ê¸°\n",
    "    draw.rectangle([x1, y1, x2, y2], fill=noise_color)\n",
    "    return image\n",
    "\n",
    "\n",
    "# ë°ì´í„°ì…‹ ì¦ê°• ë° ë³€í™˜ ì ìš©\n",
    "augmented_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(20),  # -20ë„ ~ 20ë„ íšŒì „\n",
    "    transforms.RandomHorizontalFlip(),  # 50% í™•ë¥ ë¡œ ì¢Œìš° ë°˜ì „\n",
    "    transforms.Lambda(lambda img: add_rectangle_noise(img)),  # ëœë¤í•œ ì‚¬ê°í˜• ë…¸ì´ì¦ˆ ì¶”ê°€\n",
    "    ConvNeXt_transformer  # ê¸°ë³¸ ë³€í™˜ ì ìš©\n",
    "])\n",
    "\n",
    "# ì›ë³¸ê³¼ ì¦ê°• ë°ì´í„°ì…‹ì„ ê°ê° ìƒì„±\n",
    "train_data_original = ImageFolder(root=train_dir, transform=ConvNeXt_transformer)  # ì›ë³¸ ë°ì´í„°\n",
    "train_data_augmented = ImageFolder(root=train_dir, transform=augmented_transform)  # ì¦ê°• ë°ì´í„°\n",
    "\n",
    "validation_data_original = ImageFolder(root=val_dir, transform=ConvNeXt_transformer)  # ê²€ì¦ ì›ë³¸ ë°ì´í„°\n",
    "validation_data_augmented = ImageFolder(root=val_dir, transform=augmented_transform)  # ê²€ì¦ ì¦ê°• ë°ì´í„°\n",
    "\n",
    "# ê²°í•©\n",
    "train_data_transformed = torch.utils.data.ConcatDataset([train_data_original, train_data_augmented])\n",
    "validation_data_transformed = torch.utils.data.ConcatDataset([validation_data_original, validation_data_augmented])\n",
    "\n",
    "print(f\"Original dataset size: {len(train_data_original)}\")\n",
    "print(f\"Augmented dataset size: {len(train_data_augmented)}\")\n",
    "print(f\"Combined dataset size: {len(train_data_transformed)}\")\n",
    "print(f\"Validation dataset szie: {len(validation_data_transformed)}\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "test_data_transformed = ImageFolder(root=test_dir, transform=ConvNeXt_transformer)\n",
    "\n",
    "# ë³€í™˜ëœ ë°ì´í„°ì…‹ í™•ì¸\n",
    "print(train_data_original, '\\n\\n', train_data_augmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZqH-bzQ900p"
   },
   "source": [
    "## 04 Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ZKAfXg840X0"
   },
   "outputs": [],
   "source": [
    "# ë°°ì¹˜ í¬ê¸° ë° ì›Œì»¤(worker) ìˆ˜ ì„¤ì •\n",
    "BATCH_SIZE = 64  # í•œ ë²ˆì— í•™ìŠµí•  ë°ì´í„° ìƒ˜í”Œ ìˆ˜\n",
    "NUM_WORKERS = os.cpu_count()  # ì‚¬ìš©í•  CPU ì½”ì–´ ê°œìˆ˜ (ìµœëŒ€ ì„±ëŠ¥ í™œìš©)\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„° ë¡œë” ìƒì„±\n",
    "train_dataloader = DataLoader(dataset=train_data_transformed,  # í•™ìŠµ ë°ì´í„°ì…‹\n",
    "                              batch_size=BATCH_SIZE,  # ë°°ì¹˜ í¬ê¸° ì„¤ì •\n",
    "                              num_workers=NUM_WORKERS,  # CPU ì›Œì»¤ ê°œìˆ˜ ì„¤ì •\n",
    "                              shuffle=True,  # í•™ìŠµ ë°ì´í„°ëŠ” ëœë¤ìœ¼ë¡œ ì„ì–´ì„œ ë¡œë“œ\n",
    "                              pin_memory=True)  # CUDA ì‚¬ìš© ì‹œ ë©”ëª¨ë¦¬ í•€ ì„¤ì • (ì†ë„ í–¥ìƒ)\n",
    "\n",
    "# ê²€ì¦ ë°ì´í„° ë¡œë” ìƒì„±\n",
    "validation_dataloader = DataLoader(dataset=validation_data_transformed,\n",
    "                                   batch_size=BATCH_SIZE,\n",
    "                                   num_workers=NUM_WORKERS,\n",
    "                                   shuffle=False,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„±\n",
    "test_dataloader = DataLoader(dataset=test_data_transformed,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             num_workers=NUM_WORKERS,\n",
    "                             shuffle=False,\n",
    "                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LU-w3xJ7AcW"
   },
   "source": [
    "## 05 Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7208,
     "status": "ok",
     "timestamp": 1743317179140,
     "user": {
      "displayName": "ì´ìˆ˜ì¸",
      "userId": "16249151905029041959"
     },
     "user_tz": -540
    },
    "id": "T_lk-Fud8uXk",
    "outputId": "08d34535-aa7f-4fbf-fa1f-5c52a86e3b66"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/convnext_base-6075fbad.pth\" to /root/.cache/torch/hub/checkpoints/convnext_base-6075fbad.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 338M/338M [00:03<00:00, 90.7MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===========================================================================================================================================================\n",
       "Layer (type (var_name))                                 Input Shape               Output Shape              Param #                   Trainable\n",
       "===========================================================================================================================================================\n",
       "ConvNeXt (ConvNeXt)                                     [32, 3, 224, 224]         [32, 36]                  --                        Partial\n",
       "â”œâ”€Sequential (features)                                 [32, 3, 224, 224]         [32, 1024, 7, 7]          --                        False\n",
       "â”‚    â””â”€Conv2dNormActivation (0)                         [32, 3, 224, 224]         [32, 128, 56, 56]         --                        False\n",
       "â”‚    â”‚    â””â”€Conv2d (0)                                  [32, 3, 224, 224]         [32, 128, 56, 56]         (6,272)                   False\n",
       "â”‚    â”‚    â””â”€LayerNorm2d (1)                             [32, 128, 56, 56]         [32, 128, 56, 56]         (256)                     False\n",
       "â”‚    â””â”€Sequential (1)                                   [32, 128, 56, 56]         [32, 128, 56, 56]         --                        False\n",
       "â”‚    â”‚    â””â”€CNBlock (0)                                 [32, 128, 56, 56]         [32, 128, 56, 56]         (138,496)                 False\n",
       "â”‚    â”‚    â””â”€CNBlock (1)                                 [32, 128, 56, 56]         [32, 128, 56, 56]         (138,496)                 False\n",
       "â”‚    â”‚    â””â”€CNBlock (2)                                 [32, 128, 56, 56]         [32, 128, 56, 56]         (138,496)                 False\n",
       "â”‚    â””â”€Sequential (2)                                   [32, 128, 56, 56]         [32, 256, 28, 28]         --                        False\n",
       "â”‚    â”‚    â””â”€LayerNorm2d (0)                             [32, 128, 56, 56]         [32, 128, 56, 56]         (256)                     False\n",
       "â”‚    â”‚    â””â”€Conv2d (1)                                  [32, 128, 56, 56]         [32, 256, 28, 28]         (131,328)                 False\n",
       "â”‚    â””â”€Sequential (3)                                   [32, 256, 28, 28]         [32, 256, 28, 28]         --                        False\n",
       "â”‚    â”‚    â””â”€CNBlock (0)                                 [32, 256, 28, 28]         [32, 256, 28, 28]         (539,136)                 False\n",
       "â”‚    â”‚    â””â”€CNBlock (1)                                 [32, 256, 28, 28]         [32, 256, 28, 28]         (539,136)                 False\n",
       "â”‚    â”‚    â””â”€CNBlock (2)                                 [32, 256, 28, 28]         [32, 256, 28, 28]         (539,136)                 False\n",
       "â”‚    â””â”€Sequential (4)                                   [32, 256, 28, 28]         [32, 512, 14, 14]         --                        False\n",
       "â”‚    â”‚    â””â”€LayerNorm2d (0)                             [32, 256, 28, 28]         [32, 256, 28, 28]         (512)                     False\n",
       "â”‚    â”‚    â””â”€Conv2d (1)                                  [32, 256, 28, 28]         [32, 512, 14, 14]         (524,800)                 False\n",
       "â”‚    â””â”€Sequential (5)                                   [32, 512, 14, 14]         [32, 512, 14, 14]         --                        False\n",
       "â”‚    â”‚    â””â”€CNBlock (0)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (1)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (2)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (3)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (4)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (5)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (6)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (7)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (8)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (9)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (10)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (11)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (12)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (13)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (14)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (15)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (16)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (17)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (18)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (19)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (20)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (21)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (22)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (23)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (24)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (25)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (26)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "â”‚    â””â”€Sequential (6)                                   [32, 512, 14, 14]         [32, 1024, 7, 7]          --                        False\n",
       "â”‚    â”‚    â””â”€LayerNorm2d (0)                             [32, 512, 14, 14]         [32, 512, 14, 14]         (1,024)                   False\n",
       "â”‚    â”‚    â””â”€Conv2d (1)                                  [32, 512, 14, 14]         [32, 1024, 7, 7]          (2,098,176)               False\n",
       "â”‚    â””â”€Sequential (7)                                   [32, 1024, 7, 7]          [32, 1024, 7, 7]          --                        False\n",
       "â”‚    â”‚    â””â”€CNBlock (0)                                 [32, 1024, 7, 7]          [32, 1024, 7, 7]          (8,448,000)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (1)                                 [32, 1024, 7, 7]          [32, 1024, 7, 7]          (8,448,000)               False\n",
       "â”‚    â”‚    â””â”€CNBlock (2)                                 [32, 1024, 7, 7]          [32, 1024, 7, 7]          (8,448,000)               False\n",
       "â”œâ”€AdaptiveAvgPool2d (avgpool)                           [32, 1024, 7, 7]          [32, 1024, 1, 1]          --                        --\n",
       "â”œâ”€Sequential (classifier)                               [32, 1024, 1, 1]          [32, 36]                  --                        True\n",
       "â”‚    â””â”€Flatten (0)                                      [32, 1024, 1, 1]          [32, 1024]                --                        --\n",
       "â”‚    â””â”€LayerNorm (1)                                    [32, 1024]                [32, 1024]                2,048                     True\n",
       "â”‚    â””â”€Linear (2)                                       [32, 1024]                [32, 36]                  36,900                    True\n",
       "===========================================================================================================================================================\n",
       "Total params: 87,603,364\n",
       "Trainable params: 38,948\n",
       "Non-trainable params: 87,564,416\n",
       "Total mult-adds (Units.GIGABYTES): 20.66\n",
       "===========================================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 8837.67\n",
       "Params size (MB): 350.34\n",
       "Estimated Total Size (MB): 9207.28\n",
       "==========================================================================================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ConvNeXt-Base ëª¨ë¸ ìƒì„± ë° ì‚¬ì „í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì ìš©\n",
    "ConvNeXt_model = models.convnext_base(weights=ConvNeXt_weights).to(device)\n",
    "\n",
    "# íŠ¹ì§• ì¶”ì¶œê¸°(Feature Extractor) ë¶€ë¶„ ë™ê²°\n",
    "for param in ConvNeXt_model.features.parameters():\n",
    "    param.requires_grad = False # ê¸°ì¡´ ê°€ì¤‘ì¹˜ë¥¼ ê³ ì •í•˜ì—¬ í•™ìŠµë˜ì§€ ì•Šë„ë¡ ì„¤ì •\n",
    "\n",
    "# ëœë¤ ì‹œë“œ ê³ ì •\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# ë¶„ë¥˜ê¸°(Classifier) ë ˆì´ì–´ ì¬êµ¬ì„±\n",
    "ConvNeXt_model.classifier = nn.Sequential(\n",
    "    nn.Flatten(1),  # í…ì„œë¥¼ 1ì°¨ì›ìœ¼ë¡œ í‰íƒ„í™”\n",
    "    nn.LayerNorm(normalized_shape=(1024,), eps=1e-06, elementwise_affine=True),  # ì •ê·œí™”\n",
    "    nn.Linear(in_features=1024, out_features=len(class_labels)) # ì¶œë ¥ ë‰´ëŸ° ìˆ˜ë¥¼ í´ë˜ìŠ¤ ê°œìˆ˜(len(class_labels))ë¡œ ì„¤ì •\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ë””ë°”ì´ìŠ¤ ì´ë™\n",
    "ConvNeXt_model = ConvNeXt_model.to(device)\n",
    "\n",
    "# ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ì—¬ ë³€ê²½ëœ ë¶€ë¶„ì„ í™•ì¸\n",
    "summary(model=ConvNeXt_model,\n",
    "        input_size=[32, 3, 224, 224], # ì…ë ¥ ë°ì´í„° í¬ê¸° (batch_size=32, ì±„ë„=3, ë†’ì´=224, ë„ˆë¹„=224)\n",
    "        col_names=['input_size', 'output_size', 'num_params', 'trainable'],  # ì¶œë ¥í•  ì •ë³´ ì„¤ì •\n",
    "        row_settings=['var_names']) # ë³€ìˆ˜ëª… ì¶œë ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTb6cKqF83it"
   },
   "source": [
    "## 06 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H--aT8R1866W"
   },
   "outputs": [],
   "source": [
    "def update_ema(ema_model: OrderedDict, model: torch.nn.Module, decay: float):\n",
    "    with torch.no_grad():\n",
    "        model_state = model.state_dict()\n",
    "        for name, param in model_state.items():\n",
    "            if param.dtype in (torch.float16, torch.float32, torch.float64):  # EMA ëŒ€ìƒ\n",
    "                if name in ema_model:\n",
    "                    ema_model[name].mul_(decay).add_(param, alpha=1 - decay)\n",
    "                else:\n",
    "                    ema_model[name] = param.clone()\n",
    "\n",
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    ë‹¨ì¼ í•™ìŠµ ìŠ¤í…ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    model.train()  # í•™ìŠµ ëª¨ë“œ ì„¤ì •\n",
    "    train_loss, train_acc = 0, 0  # í•™ìŠµ ì†ì‹¤ ë° ì •í™•ë„ ì´ˆê¸°í™”\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)  # ì…ë ¥ ë°ì´í„°ì™€ ë¼ë²¨ì„ ì§€ì •ëœ ì¥ì¹˜ë¡œ ì´ë™\n",
    "        optimizer.zero_grad()  # ì´ì „ ë‹¨ê³„ì˜ ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "        y_pred = model(X)  # ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "        loss = loss_fn(y_pred, y)  # ì†ì‹¤ ê³„ì‚°\n",
    "        loss.backward()  # ì—­ì „íŒŒ(Backpropagation)\n",
    "        optimizer.step()  # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "\n",
    "        train_loss += loss.item()  # ì†ì‹¤ í•©ì‚°\n",
    "        acc = (y_pred.argmax(dim=1) == y).sum().item() / len(y)  # ì •í™•ë„ ê³„ì‚°\n",
    "        train_acc += acc  # ì •í™•ë„ í•©ì‚°\n",
    "\n",
    "    return train_loss / len(dataloader), train_acc / len(dataloader)  # í‰ê·  ì†ì‹¤ ë° ì •í™•ë„ ë°˜í™˜\n",
    "\n",
    "\n",
    "def eval_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    ë‹¨ì¼ í‰ê°€ ìŠ¤í…ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    model.eval()  # í‰ê°€ ëª¨ë“œ ì„¤ì •\n",
    "    eval_loss, eval_acc = 0, 0  # í‰ê°€ ì†ì‹¤ ë° ì •í™•ë„ ì´ˆê¸°í™”\n",
    "\n",
    "    with torch.inference_mode():  # í‰ê°€ ì‹œ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™” (ì†ë„ í–¥ìƒ)\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)  # ì…ë ¥ ë°ì´í„°ì™€ ë¼ë²¨ì„ ì§€ì •ëœ ì¥ì¹˜ë¡œ ì´ë™\n",
    "            y_pred = model(X)  # ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "            loss = loss_fn(y_pred, y)  # ì†ì‹¤ ê³„ì‚°\n",
    "            eval_loss += loss.item()  # ì†ì‹¤ í•©ì‚°\n",
    "            acc = (y_pred.argmax(dim=1) == y).sum().item() / len(y)  # ì •í™•ë„ ê³„ì‚°\n",
    "            eval_acc += acc  # ì •í™•ë„ í•©ì‚°\n",
    "\n",
    "    return eval_loss / len(dataloader), eval_acc / len(dataloader)  # í‰ê·  ì†ì‹¤ ë° ì •í™•ë„ ë°˜í™˜\n",
    "\n",
    "\n",
    "def train_eval(model: torch.nn.Module,\n",
    "               train_dataloader: torch.utils.data.DataLoader,\n",
    "               val_dataloader: torch.utils.data.DataLoader,\n",
    "               epochs: int,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device) -> List[Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    ì§€ì •ëœ ì—í¬í¬(epochs) ë™ì•ˆ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê°€í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    results = []  # í•™ìŠµ ë° í‰ê°€ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "    ema_params = OrderedDict()  # EMA(ì§€ìˆ˜ì´ë™í‰ê· )ë¥¼ ìœ„í•œ íŒŒë¼ë¯¸í„° ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬\n",
    "    ema_decay = 0.9999  # EMA ì ìš© ì‹œ ì‚¬ìš©ë  decay ê°’ (ê°€ì¤‘ì¹˜ í‰ê·  ë¹„ìœ¨)\n",
    "\n",
    "    # ì „ì²´ í•™ìŠµ ì‹œì‘ ì‹œê°„ ê¸°ë¡\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # í•™ìŠµ ë‹¨ê³„ ìˆ˜í–‰\n",
    "        train_loss, train_acc = train_step(model, train_dataloader, loss_fn, optimizer, device)\n",
    "        # EMA(ì§€ìˆ˜ ì´ë™ í‰ê· ) íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ â€“ ëª¨ë¸ íŒŒë¼ë¯¸í„°ì˜ í‰ê· ì„ ì €ì¥í•˜ì—¬ ì•ˆì •ì ì¸ í‰ê°€ì— ì‚¬ìš©\n",
    "        update_ema(ema_params, model, ema_decay)\n",
    "        # í‰ê°€ ë‹¨ê³„ ìˆ˜í–‰\n",
    "        val_loss, val_acc = eval_step(model, val_dataloader, loss_fn, device)\n",
    "\n",
    "        # í˜„ì¬ í•™ìŠµë¥  í™•ì¸\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # í•™ìŠµ ë° í‰ê°€ ê²°ê³¼ ì¶œë ¥\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: \\n\"\n",
    "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} \\n\"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | LR: {current_lr:.6f}\")\n",
    "\n",
    "        # ê²°ê³¼ ì €ì¥\n",
    "        results.append({\n",
    "            \"epoch\": epoch+1,\n",
    "            \"Train_loss\": train_loss,\n",
    "            \"Train_acc\": train_acc,\n",
    "            \"Val_loss\": val_loss,\n",
    "            \"Val_acc\": val_acc,\n",
    "            \"lr\": current_lr\n",
    "        })\n",
    "\n",
    "    # EMA íŒŒë¼ë¯¸í„° ë°±ì—… ë° ì ìš©\n",
    "    original_params = {name: param.data.clone() for name, param in model.named_parameters() if name in ema_params}\n",
    "    for name, param in model.named_parameters():\n",
    "        if name in ema_params:\n",
    "            param.data.copy_(ema_params[name])\n",
    "\n",
    "    ema_val_loss, ema_val_acc = eval_step(model, val_dataloader, loss_fn, device)\n",
    "    print(f\"EMA Validation Accuracy: {ema_val_acc:.4f} | EMA Validation Loss: {ema_val_loss:.4f}\")\n",
    "\n",
    "    # ì›ë˜ íŒŒë¼ë¯¸í„° ë³µì›\n",
    "    for name, param in model.named_parameters():\n",
    "        if name in original_params:\n",
    "            param.data.copy_(original_params[name])\n",
    "\n",
    "\n",
    "    # ì „ì²´ í•™ìŠµ ë ì‹œê°„ ê¸°ë¡\n",
    "    total_end_time = time.time()\n",
    "    print(f\"\\nğŸ•’ ì „ì²´ í•™ìŠµ ì‹œê°„: {(total_end_time - total_start_time) / 60:.2f}ë¶„\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vn_JgivHBHCX"
   },
   "source": [
    "### train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2809475,
     "status": "ok",
     "timestamp": 1743319988641,
     "user": {
      "displayName": "ì´ìˆ˜ì¸",
      "userId": "16249151905029041959"
     },
     "user_tz": -540
    },
    "id": "4WB-cTuvVyNY",
    "outputId": "6f998ecb-23c3-40b0-8697-a7a429cfe6b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: \n",
      "Train Loss: 1.1046 | Train Acc: 0.7161 \n",
      "Val Loss: 0.4095 | Val Acc: 0.8731 | LR: 0.001000\n",
      "Epoch 2/50: \n",
      "Train Loss: 0.4602 | Train Acc: 0.8586 \n",
      "Val Loss: 0.3043 | Val Acc: 0.8963 | LR: 0.001000\n",
      "Epoch 3/50: \n",
      "Train Loss: 0.3620 | Train Acc: 0.8833 \n",
      "Val Loss: 0.2685 | Val Acc: 0.9062 | LR: 0.001000\n",
      "Epoch 4/50: \n",
      "Train Loss: 0.3048 | Train Acc: 0.9031 \n",
      "Val Loss: 0.2526 | Val Acc: 0.9104 | LR: 0.001000\n",
      "Epoch 5/50: \n",
      "Train Loss: 0.2645 | Train Acc: 0.9133 \n",
      "Val Loss: 0.2432 | Val Acc: 0.9119 | LR: 0.001000\n",
      "Epoch 6/50: \n",
      "Train Loss: 0.2427 | Train Acc: 0.9216 \n",
      "Val Loss: 0.2131 | Val Acc: 0.9204 | LR: 0.001000\n",
      "Epoch 7/50: \n",
      "Train Loss: 0.2206 | Train Acc: 0.9270 \n",
      "Val Loss: 0.1940 | Val Acc: 0.9375 | LR: 0.001000\n",
      "Epoch 8/50: \n",
      "Train Loss: 0.1998 | Train Acc: 0.9335 \n",
      "Val Loss: 0.1982 | Val Acc: 0.9148 | LR: 0.001000\n",
      "Epoch 9/50: \n",
      "Train Loss: 0.1909 | Train Acc: 0.9345 \n",
      "Val Loss: 0.1894 | Val Acc: 0.9303 | LR: 0.001000\n",
      "Epoch 10/50: \n",
      "Train Loss: 0.1856 | Train Acc: 0.9329 \n",
      "Val Loss: 0.2075 | Val Acc: 0.9244 | LR: 0.001000\n",
      "Epoch 11/50: \n",
      "Train Loss: 0.1817 | Train Acc: 0.9342 \n",
      "Val Loss: 0.2006 | Val Acc: 0.9417 | LR: 0.001000\n",
      "Epoch 12/50: \n",
      "Train Loss: 0.1715 | Train Acc: 0.9388 \n",
      "Val Loss: 0.1885 | Val Acc: 0.9416 | LR: 0.001000\n",
      "Epoch 13/50: \n",
      "Train Loss: 0.1573 | Train Acc: 0.9450 \n",
      "Val Loss: 0.1828 | Val Acc: 0.9318 | LR: 0.001000\n",
      "Epoch 14/50: \n",
      "Train Loss: 0.1598 | Train Acc: 0.9437 \n",
      "Val Loss: 0.1890 | Val Acc: 0.9387 | LR: 0.001000\n",
      "Epoch 15/50: \n",
      "Train Loss: 0.1489 | Train Acc: 0.9474 \n",
      "Val Loss: 0.1708 | Val Acc: 0.9445 | LR: 0.001000\n",
      "Epoch 16/50: \n",
      "Train Loss: 0.1442 | Train Acc: 0.9520 \n",
      "Val Loss: 0.1664 | Val Acc: 0.9516 | LR: 0.001000\n",
      "Epoch 17/50: \n",
      "Train Loss: 0.1415 | Train Acc: 0.9515 \n",
      "Val Loss: 0.1606 | Val Acc: 0.9417 | LR: 0.001000\n",
      "Epoch 18/50: \n",
      "Train Loss: 0.1395 | Train Acc: 0.9517 \n",
      "Val Loss: 0.1835 | Val Acc: 0.9402 | LR: 0.001000\n",
      "Epoch 19/50: \n",
      "Train Loss: 0.1457 | Train Acc: 0.9453 \n",
      "Val Loss: 0.1714 | Val Acc: 0.9545 | LR: 0.001000\n",
      "Epoch 20/50: \n",
      "Train Loss: 0.1321 | Train Acc: 0.9536 \n",
      "Val Loss: 0.1607 | Val Acc: 0.9501 | LR: 0.001000\n",
      "Epoch 21/50: \n",
      "Train Loss: 0.1283 | Train Acc: 0.9541 \n",
      "Val Loss: 0.1627 | Val Acc: 0.9601 | LR: 0.001000\n",
      "Epoch 22/50: \n",
      "Train Loss: 0.1257 | Train Acc: 0.9547 \n",
      "Val Loss: 0.1836 | Val Acc: 0.9432 | LR: 0.001000\n",
      "Epoch 23/50: \n",
      "Train Loss: 0.1308 | Train Acc: 0.9514 \n",
      "Val Loss: 0.1824 | Val Acc: 0.9530 | LR: 0.001000\n",
      "Epoch 24/50: \n",
      "Train Loss: 0.1213 | Train Acc: 0.9546 \n",
      "Val Loss: 0.1807 | Val Acc: 0.9430 | LR: 0.001000\n",
      "Epoch 25/50: \n",
      "Train Loss: 0.1308 | Train Acc: 0.9493 \n",
      "Val Loss: 0.1679 | Val Acc: 0.9529 | LR: 0.001000\n",
      "Epoch 26/50: \n",
      "Train Loss: 0.1195 | Train Acc: 0.9567 \n",
      "Val Loss: 0.1581 | Val Acc: 0.9615 | LR: 0.001000\n",
      "Epoch 27/50: \n",
      "Train Loss: 0.1168 | Train Acc: 0.9576 \n",
      "Val Loss: 0.1609 | Val Acc: 0.9530 | LR: 0.001000\n",
      "Epoch 28/50: \n",
      "Train Loss: 0.1162 | Train Acc: 0.9573 \n",
      "Val Loss: 0.1752 | Val Acc: 0.9516 | LR: 0.001000\n",
      "Epoch 29/50: \n",
      "Train Loss: 0.1154 | Train Acc: 0.9586 \n",
      "Val Loss: 0.1657 | Val Acc: 0.9460 | LR: 0.001000\n",
      "Epoch 30/50: \n",
      "Train Loss: 0.1107 | Train Acc: 0.9578 \n",
      "Val Loss: 0.1634 | Val Acc: 0.9488 | LR: 0.001000\n",
      "Epoch 31/50: \n",
      "Train Loss: 0.1091 | Train Acc: 0.9614 \n",
      "Val Loss: 0.1632 | Val Acc: 0.9458 | LR: 0.001000\n",
      "Epoch 32/50: \n",
      "Train Loss: 0.1075 | Train Acc: 0.9578 \n",
      "Val Loss: 0.1921 | Val Acc: 0.9347 | LR: 0.001000\n",
      "Epoch 33/50: \n",
      "Train Loss: 0.1124 | Train Acc: 0.9574 \n",
      "Val Loss: 0.1539 | Val Acc: 0.9587 | LR: 0.001000\n",
      "Epoch 34/50: \n",
      "Train Loss: 0.1062 | Train Acc: 0.9629 \n",
      "Val Loss: 0.1569 | Val Acc: 0.9531 | LR: 0.001000\n",
      "Epoch 35/50: \n",
      "Train Loss: 0.1062 | Train Acc: 0.9598 \n",
      "Val Loss: 0.1747 | Val Acc: 0.9474 | LR: 0.001000\n",
      "Epoch 36/50: \n",
      "Train Loss: 0.1074 | Train Acc: 0.9589 \n",
      "Val Loss: 0.1723 | Val Acc: 0.9544 | LR: 0.001000\n",
      "Epoch 37/50: \n",
      "Train Loss: 0.1055 | Train Acc: 0.9597 \n",
      "Val Loss: 0.1663 | Val Acc: 0.9545 | LR: 0.001000\n",
      "Epoch 38/50: \n",
      "Train Loss: 0.1029 | Train Acc: 0.9638 \n",
      "Val Loss: 0.1824 | Val Acc: 0.9474 | LR: 0.001000\n",
      "Epoch 39/50: \n",
      "Train Loss: 0.1050 | Train Acc: 0.9594 \n",
      "Val Loss: 0.1864 | Val Acc: 0.9543 | LR: 0.001000\n",
      "Epoch 40/50: \n",
      "Train Loss: 0.1035 | Train Acc: 0.9606 \n",
      "Val Loss: 0.1735 | Val Acc: 0.9600 | LR: 0.001000\n",
      "Epoch 41/50: \n",
      "Train Loss: 0.1000 | Train Acc: 0.9624 \n",
      "Val Loss: 0.1845 | Val Acc: 0.9474 | LR: 0.001000\n",
      "Epoch 42/50: \n",
      "Train Loss: 0.0979 | Train Acc: 0.9632 \n",
      "Val Loss: 0.1630 | Val Acc: 0.9559 | LR: 0.001000\n",
      "Epoch 43/50: \n",
      "Train Loss: 0.1059 | Train Acc: 0.9589 \n",
      "Val Loss: 0.1996 | Val Acc: 0.9559 | LR: 0.001000\n",
      "Epoch 44/50: \n",
      "Train Loss: 0.0932 | Train Acc: 0.9649 \n",
      "Val Loss: 0.1582 | Val Acc: 0.9658 | LR: 0.001000\n",
      "Epoch 45/50: \n",
      "Train Loss: 0.0921 | Train Acc: 0.9670 \n",
      "Val Loss: 0.1620 | Val Acc: 0.9687 | LR: 0.001000\n",
      "Epoch 46/50: \n",
      "Train Loss: 0.0954 | Train Acc: 0.9636 \n",
      "Val Loss: 0.1737 | Val Acc: 0.9572 | LR: 0.001000\n",
      "Epoch 47/50: \n",
      "Train Loss: 0.0918 | Train Acc: 0.9627 \n",
      "Val Loss: 0.1775 | Val Acc: 0.9530 | LR: 0.001000\n",
      "Epoch 48/50: \n",
      "Train Loss: 0.0971 | Train Acc: 0.9616 \n",
      "Val Loss: 0.1557 | Val Acc: 0.9574 | LR: 0.001000\n",
      "Epoch 49/50: \n",
      "Train Loss: 0.0967 | Train Acc: 0.9643 \n",
      "Val Loss: 0.1737 | Val Acc: 0.9588 | LR: 0.001000\n",
      "Epoch 50/50: \n",
      "Train Loss: 0.0942 | Train Acc: 0.9675 \n",
      "Val Loss: 0.1791 | Val Acc: 0.9530 | LR: 0.001000\n",
      "EMA Validation Accuracy: 0.8744 | EMA Validation Loss: 0.4029\n",
      "\n",
      "ğŸ•’ ì „ì²´ í•™ìŠµ ì‹œê°„: 46.82ë¶„\n"
     ]
    }
   ],
   "source": [
    "# ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”\n",
    "loss_fn = nn.CrossEntropyLoss()  # ë‹¤ì¤‘ ë¶„ë¥˜ ë¬¸ì œì— ì í•©í•œ í¬ë¡œìŠ¤ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ í•¨ìˆ˜ ì‚¬ìš©\n",
    "optimizer = torch.optim.AdamW(ConvNeXt_model.parameters(), lr=0.001)  # AdamW ì˜µí‹°ë§ˆì´ì € ì‚¬ìš©, í•™ìŠµë¥ (lr) ì„¤ì •\n",
    "\n",
    "# í•™ìŠµí•  ì´ ì—í¬í¬ ìˆ˜ ì„¤ì •\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "# í•™ìŠµ ì‹¤í–‰\n",
    "results = train_eval(model=ConvNeXt_model,\n",
    "                     train_dataloader=train_dataloader,\n",
    "                     val_dataloader=validation_dataloader,\n",
    "                     epochs=NUM_EPOCHS,\n",
    "                     loss_fn=loss_fn,\n",
    "                     optimizer=optimizer,\n",
    "                     device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nizwunc-T_he"
   },
   "source": [
    "## 07 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGNESaqNKDgv"
   },
   "outputs": [],
   "source": [
    "# ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F1_84555J13C"
   },
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì…‹ í‰ê°€\n",
    "test_loss, test_acc = eval_step(model=ConvNeXt_model,\n",
    "                                dataloader=test_dataloader,\n",
    "                                loss_fn=loss_fn,\n",
    "                                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1743320005443,
     "user": {
      "displayName": "ì´ìˆ˜ì¸",
      "userId": "16249151905029041959"
     },
     "user_tz": -540
    },
    "id": "cbyA64udJ3JD",
    "outputId": "7a366fe3-e660-419d-f3d3-4a8f6b30beef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.966146\n",
      "Test Loss: 0.147261\n"
     ]
    }
   ],
   "source": [
    "# ê²°ê³¼\n",
    "print(f\"Test accuracy: {test_acc:.6f}\")\n",
    "print(f\"Test Loss: {test_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-7Cj8cS7XkU"
   },
   "source": [
    "## 08 DB ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5105,
     "status": "ok",
     "timestamp": 1743320010550,
     "user": {
      "displayName": "ì´ìˆ˜ì¸",
      "userId": "16249151905029041959"
     },
     "user_tz": -540
    },
    "id": "qqYNjhSO7aEv",
    "outputId": "9456b302-94b5-41df-c8ca-21a49d47d68a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# DB ì—°ê²° ì •ë³´ ì…ë ¥ (Aiven MySQL ê¸°ì¤€)\n",
    "host = 'YOUR_AIVEN_HOST'\n",
    "port = 'YOUR_AIVEN_PORT'\n",
    "username = 'YOUR_USERNAME'\n",
    "password = 'YOUR_PASSWORD'\n",
    "database = 'YOUR_DATABASE'\n",
    "\n",
    "# SQLAlchemy ì—”ì§„ ìƒì„±\n",
    "engine = create_engine(f\"mysql+pymysql://{username}:{password}@{host}:{port}/{database}\")\n",
    "# DataFrameì„ MySQLì— ì €ì¥\n",
    "results_df.to_sql(name='train_logs_convnextnet', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "test_result_df = pd.DataFrame([{\n",
    "    \"model_name\": \"ConvNeXt\",\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_acc\": test_acc\n",
    "}])\n",
    "\n",
    "test_result_df.to_sql(name='test_results', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkzlX8FEBOMQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMH/tjwGDFZ0I8Z+rw1hWQz",
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "1y45MMfWg46lSc-ksTmRQTLv9EXgEgYaz",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
