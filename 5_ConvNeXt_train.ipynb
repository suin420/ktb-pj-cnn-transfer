{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsUk7PvBnt7q"
   },
   "source": [
    "## 00 Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0RSLLBJc22tE"
   },
   "outputs": [],
   "source": [
    "# !pip install torchinfo\n",
    "# !pip install modules\n",
    "# !pip install pymysql sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfjalG9B24DQ"
   },
   "source": [
    "## 01 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sedXL5wU28a8"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from collections import OrderedDict # ema에서 사용\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchinfo import summary\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "# 디바이스 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "es5nnCzExTJ7"
   },
   "source": [
    "## 02 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2iirxuwWUYku"
   },
   "outputs": [],
   "source": [
    "# 데이터 경로 설정\n",
    "data_dir = 'your_path/fruit-and-vegetable-image'\n",
    "\n",
    "# 데이터 불러오기\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "train_filepaths = list(Path(train_dir).rglob('*.jpg')) + \\\n",
    "                  list(Path(train_dir).rglob('*.jpeg')) + \\\n",
    "                  list(Path(train_dir).rglob('*.png')) + \\\n",
    "                  list(Path(train_dir).rglob('*.JPG'))\n",
    "\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "test_filepaths = list(Path(test_dir).rglob('*.jpg')) + \\\n",
    "                 list(Path(test_dir).rglob('*.jpeg')) + \\\n",
    "                 list(Path(test_dir).rglob('*.png')) + \\\n",
    "                 list(Path(test_dir).rglob('*.JPG'))\n",
    "\n",
    "val_dir = os.path.join(data_dir, 'validation')\n",
    "val_filepaths = list(Path(val_dir).rglob('*.jpg')) + \\\n",
    "                 list(Path(val_dir).rglob('*.jpeg')) + \\\n",
    "                 list(Path(val_dir).rglob('*.png')) + \\\n",
    "                 list(Path(val_dir).rglob('*.JPG'))\n",
    "\n",
    "\n",
    "def proc_img(filepath):\n",
    "    \"\"\"\n",
    "    이미지 파일의 경로와 라벨을 포함하는 DataFrame을 생성하는 함수\n",
    "    \"\"\"\n",
    "\n",
    "    # 파일 경로에서 라벨(폴더명) 추출\n",
    "    labels = [str(filepath[i]).split(\"/\")[-2] for i in range(len(filepath))]\n",
    "\n",
    "    # 파일 경로를 pandas Series로 변환하고 문자열로 저장\n",
    "    filepath = pd.Series(filepath, name='Filepath').astype(str)\n",
    "\n",
    "    # 라벨을 pandas Series로 변환\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    # 파일 경로와 라벨을 하나의 DataFrame으로 합치기\n",
    "    df = pd.concat([filepath, labels], axis=1)\n",
    "\n",
    "    # 데이터 프레임을 랜덤하게 섞고 인덱스 초기화\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# 학습(train), 테스트(test), 검증(validation) 데이터 프레임 생성\n",
    "train_df = proc_img(train_filepaths)\n",
    "test_df = proc_img(test_filepaths)\n",
    "val_df = proc_img(val_filepaths)\n",
    "\n",
    "# 클래스 목록 가져오기\n",
    "class_labels = train_df.Label.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWap5H_13nm1"
   },
   "source": [
    "## 03 Create Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1743317171761,
     "user": {
      "displayName": "이수인",
      "userId": "16249151905029041959"
     },
     "user_tz": -540
    },
    "id": "024RhS9w2csY",
    "outputId": "4479313e-83cf-47a2-aeb9-4f9e33474fc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[232]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BILINEAR\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ConvNeXt 모델의 기본 사전 학습된 가중치 불러오기\n",
    "ConvNeXt_weights = models.ConvNeXt_Base_Weights.DEFAULT\n",
    "\n",
    "# 해당 가중치에 맞는 변환(transform) 객체 가져오기\n",
    "ConvNeXt_transformer = ConvNeXt_weights.transforms() # 모델이 요구하는 데이터 전처리 파이프라인이 반환\n",
    "\n",
    "# 변환 객체 출력 (어떤 변환이 적용되는지 확인)\n",
    "ConvNeXt_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1743317171870,
     "user": {
      "displayName": "이수인",
      "userId": "16249151905029041959"
     },
     "user_tz": -540
    },
    "id": "XBf_Bwysucgu",
    "outputId": "6fa3c8c4-74ce-4997-c7b3-becad499598c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 3115\n",
      "Augmented dataset size: 3115\n",
      "Combined dataset size: 6230\n",
      "Validation dataset szie: 702\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 3115\n",
      "    Root location: /content/drive/MyDrive/Colab_Notebooks/fruit-and-vegetable-image/train\n",
      "    StandardTransform\n",
      "Transform: ImageClassification(\n",
      "               crop_size=[224]\n",
      "               resize_size=[232]\n",
      "               mean=[0.485, 0.456, 0.406]\n",
      "               std=[0.229, 0.224, 0.225]\n",
      "               interpolation=InterpolationMode.BILINEAR\n",
      "           ) \n",
      "\n",
      " Dataset ImageFolder\n",
      "    Number of datapoints: 3115\n",
      "    Root location: /content/drive/MyDrive/Colab_Notebooks/fruit-and-vegetable-image/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomRotation(degrees=[-20.0, 20.0], interpolation=nearest, expand=False, fill=0)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               Lambda()\n",
      "               ImageClassification(\n",
      "               crop_size=[224]\n",
      "               resize_size=[232]\n",
      "               mean=[0.485, 0.456, 0.406]\n",
      "               std=[0.229, 0.224, 0.225]\n",
      "               interpolation=InterpolationMode.BILINEAR\n",
      "           )\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# 랜덤한 사각형 노이즈 추가 함수\n",
    "def add_rectangle_noise(image):\n",
    "    \"\"\"이미지에 랜덤한 크기와 위치의 사각형 노이즈 추가\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    width, height = image.size\n",
    "\n",
    "    # 노이즈 크기 (전체 이미지 크기의 30~50%)\n",
    "    box_width = random.randint(int(0.3 * width), int(0.5 * width))\n",
    "    box_height = random.randint(int(0.3 * height), int(0.5 * height))\n",
    "\n",
    "    # 랜덤 위치\n",
    "    x1 = random.randint(0, width - box_width)\n",
    "    y1 = random.randint(0, height - box_height)\n",
    "    x2 = x1 + box_width\n",
    "    y2 = y1 + box_height\n",
    "\n",
    "    # 랜덤 색상 (0~255 범위)\n",
    "    noise_color = tuple(np.random.randint(0, 256, size=3).tolist())\n",
    "\n",
    "    # 사각형 그리기\n",
    "    draw.rectangle([x1, y1, x2, y2], fill=noise_color)\n",
    "    return image\n",
    "\n",
    "\n",
    "# 데이터셋 증강 및 변환 적용\n",
    "augmented_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(20),  # -20도 ~ 20도 회전\n",
    "    transforms.RandomHorizontalFlip(),  # 50% 확률로 좌우 반전\n",
    "    transforms.Lambda(lambda img: add_rectangle_noise(img)),  # 랜덤한 사각형 노이즈 추가\n",
    "    ConvNeXt_transformer  # 기본 변환 적용\n",
    "])\n",
    "\n",
    "# 원본과 증강 데이터셋을 각각 생성\n",
    "train_data_original = ImageFolder(root=train_dir, transform=ConvNeXt_transformer)  # 원본 데이터\n",
    "train_data_augmented = ImageFolder(root=train_dir, transform=augmented_transform)  # 증강 데이터\n",
    "\n",
    "validation_data_original = ImageFolder(root=val_dir, transform=ConvNeXt_transformer)  # 검증 원본 데이터\n",
    "validation_data_augmented = ImageFolder(root=val_dir, transform=augmented_transform)  # 검증 증강 데이터\n",
    "\n",
    "# 결합\n",
    "train_data_transformed = torch.utils.data.ConcatDataset([train_data_original, train_data_augmented])\n",
    "validation_data_transformed = torch.utils.data.ConcatDataset([validation_data_original, validation_data_augmented])\n",
    "\n",
    "print(f\"Original dataset size: {len(train_data_original)}\")\n",
    "print(f\"Augmented dataset size: {len(train_data_augmented)}\")\n",
    "print(f\"Combined dataset size: {len(train_data_transformed)}\")\n",
    "print(f\"Validation dataset szie: {len(validation_data_transformed)}\")\n",
    "\n",
    "# 테스트 데이터는 원본 그대로 유지\n",
    "test_data_transformed = ImageFolder(root=test_dir, transform=ConvNeXt_transformer)\n",
    "\n",
    "# 변환된 데이터셋 확인\n",
    "print(train_data_original, '\\n\\n', train_data_augmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZqH-bzQ900p"
   },
   "source": [
    "## 04 Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ZKAfXg840X0"
   },
   "outputs": [],
   "source": [
    "# 배치 크기 및 워커(worker) 수 설정\n",
    "BATCH_SIZE = 64  # 한 번에 학습할 데이터 샘플 수\n",
    "NUM_WORKERS = os.cpu_count()  # 사용할 CPU 코어 개수 (최대 성능 활용)\n",
    "\n",
    "# 학습 데이터 로더 생성\n",
    "train_dataloader = DataLoader(dataset=train_data_transformed,  # 학습 데이터셋\n",
    "                              batch_size=BATCH_SIZE,  # 배치 크기 설정\n",
    "                              num_workers=NUM_WORKERS,  # CPU 워커 개수 설정\n",
    "                              shuffle=True,  # 학습 데이터는 랜덤으로 섞어서 로드\n",
    "                              pin_memory=True)  # CUDA 사용 시 메모리 핀 설정 (속도 향상)\n",
    "\n",
    "# 검증 데이터 로더 생성\n",
    "validation_dataloader = DataLoader(dataset=validation_data_transformed,\n",
    "                                   batch_size=BATCH_SIZE,\n",
    "                                   num_workers=NUM_WORKERS,\n",
    "                                   shuffle=False,\n",
    "                                   pin_memory=True)\n",
    "\n",
    "# 테스트 데이터 로더 생성\n",
    "test_dataloader = DataLoader(dataset=test_data_transformed,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             num_workers=NUM_WORKERS,\n",
    "                             shuffle=False,\n",
    "                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LU-w3xJ7AcW"
   },
   "source": [
    "## 05 Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7208,
     "status": "ok",
     "timestamp": 1743317179140,
     "user": {
      "displayName": "이수인",
      "userId": "16249151905029041959"
     },
     "user_tz": -540
    },
    "id": "T_lk-Fud8uXk",
    "outputId": "08d34535-aa7f-4fbf-fa1f-5c52a86e3b66"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/convnext_base-6075fbad.pth\" to /root/.cache/torch/hub/checkpoints/convnext_base-6075fbad.pth\n",
      "100%|██████████| 338M/338M [00:03<00:00, 90.7MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===========================================================================================================================================================\n",
       "Layer (type (var_name))                                 Input Shape               Output Shape              Param #                   Trainable\n",
       "===========================================================================================================================================================\n",
       "ConvNeXt (ConvNeXt)                                     [32, 3, 224, 224]         [32, 36]                  --                        Partial\n",
       "├─Sequential (features)                                 [32, 3, 224, 224]         [32, 1024, 7, 7]          --                        False\n",
       "│    └─Conv2dNormActivation (0)                         [32, 3, 224, 224]         [32, 128, 56, 56]         --                        False\n",
       "│    │    └─Conv2d (0)                                  [32, 3, 224, 224]         [32, 128, 56, 56]         (6,272)                   False\n",
       "│    │    └─LayerNorm2d (1)                             [32, 128, 56, 56]         [32, 128, 56, 56]         (256)                     False\n",
       "│    └─Sequential (1)                                   [32, 128, 56, 56]         [32, 128, 56, 56]         --                        False\n",
       "│    │    └─CNBlock (0)                                 [32, 128, 56, 56]         [32, 128, 56, 56]         (138,496)                 False\n",
       "│    │    └─CNBlock (1)                                 [32, 128, 56, 56]         [32, 128, 56, 56]         (138,496)                 False\n",
       "│    │    └─CNBlock (2)                                 [32, 128, 56, 56]         [32, 128, 56, 56]         (138,496)                 False\n",
       "│    └─Sequential (2)                                   [32, 128, 56, 56]         [32, 256, 28, 28]         --                        False\n",
       "│    │    └─LayerNorm2d (0)                             [32, 128, 56, 56]         [32, 128, 56, 56]         (256)                     False\n",
       "│    │    └─Conv2d (1)                                  [32, 128, 56, 56]         [32, 256, 28, 28]         (131,328)                 False\n",
       "│    └─Sequential (3)                                   [32, 256, 28, 28]         [32, 256, 28, 28]         --                        False\n",
       "│    │    └─CNBlock (0)                                 [32, 256, 28, 28]         [32, 256, 28, 28]         (539,136)                 False\n",
       "│    │    └─CNBlock (1)                                 [32, 256, 28, 28]         [32, 256, 28, 28]         (539,136)                 False\n",
       "│    │    └─CNBlock (2)                                 [32, 256, 28, 28]         [32, 256, 28, 28]         (539,136)                 False\n",
       "│    └─Sequential (4)                                   [32, 256, 28, 28]         [32, 512, 14, 14]         --                        False\n",
       "│    │    └─LayerNorm2d (0)                             [32, 256, 28, 28]         [32, 256, 28, 28]         (512)                     False\n",
       "│    │    └─Conv2d (1)                                  [32, 256, 28, 28]         [32, 512, 14, 14]         (524,800)                 False\n",
       "│    └─Sequential (5)                                   [32, 512, 14, 14]         [32, 512, 14, 14]         --                        False\n",
       "│    │    └─CNBlock (0)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (1)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (2)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (3)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (4)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (5)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (6)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (7)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (8)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (9)                                 [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (10)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (11)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (12)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (13)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (14)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (15)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (16)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (17)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (18)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (19)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (20)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (21)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (22)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (23)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (24)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (25)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    │    └─CNBlock (26)                                [32, 512, 14, 14]         [32, 512, 14, 14]         (2,126,848)               False\n",
       "│    └─Sequential (6)                                   [32, 512, 14, 14]         [32, 1024, 7, 7]          --                        False\n",
       "│    │    └─LayerNorm2d (0)                             [32, 512, 14, 14]         [32, 512, 14, 14]         (1,024)                   False\n",
       "│    │    └─Conv2d (1)                                  [32, 512, 14, 14]         [32, 1024, 7, 7]          (2,098,176)               False\n",
       "│    └─Sequential (7)                                   [32, 1024, 7, 7]          [32, 1024, 7, 7]          --                        False\n",
       "│    │    └─CNBlock (0)                                 [32, 1024, 7, 7]          [32, 1024, 7, 7]          (8,448,000)               False\n",
       "│    │    └─CNBlock (1)                                 [32, 1024, 7, 7]          [32, 1024, 7, 7]          (8,448,000)               False\n",
       "│    │    └─CNBlock (2)                                 [32, 1024, 7, 7]          [32, 1024, 7, 7]          (8,448,000)               False\n",
       "├─AdaptiveAvgPool2d (avgpool)                           [32, 1024, 7, 7]          [32, 1024, 1, 1]          --                        --\n",
       "├─Sequential (classifier)                               [32, 1024, 1, 1]          [32, 36]                  --                        True\n",
       "│    └─Flatten (0)                                      [32, 1024, 1, 1]          [32, 1024]                --                        --\n",
       "│    └─LayerNorm (1)                                    [32, 1024]                [32, 1024]                2,048                     True\n",
       "│    └─Linear (2)                                       [32, 1024]                [32, 36]                  36,900                    True\n",
       "===========================================================================================================================================================\n",
       "Total params: 87,603,364\n",
       "Trainable params: 38,948\n",
       "Non-trainable params: 87,564,416\n",
       "Total mult-adds (Units.GIGABYTES): 20.66\n",
       "===========================================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 8837.67\n",
       "Params size (MB): 350.34\n",
       "Estimated Total Size (MB): 9207.28\n",
       "==========================================================================================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ConvNeXt-Base 모델 생성 및 사전학습된 가중치 적용\n",
    "ConvNeXt_model = models.convnext_base(weights=ConvNeXt_weights).to(device)\n",
    "\n",
    "# 특징 추출기(Feature Extractor) 부분 동결\n",
    "for param in ConvNeXt_model.features.parameters():\n",
    "    param.requires_grad = False # 기존 가중치를 고정하여 학습되지 않도록 설정\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# 분류기(Classifier) 레이어 재구성\n",
    "ConvNeXt_model.classifier = nn.Sequential(\n",
    "    nn.Flatten(1),  # 텐서를 1차원으로 평탄화\n",
    "    nn.LayerNorm(normalized_shape=(1024,), eps=1e-06, elementwise_affine=True),  # 정규화\n",
    "    nn.Linear(in_features=1024, out_features=len(class_labels)) # 출력 뉴런 수를 클래스 개수(len(class_labels))로 설정\n",
    ")\n",
    "\n",
    "# 모델 디바이스 이동\n",
    "ConvNeXt_model = ConvNeXt_model.to(device)\n",
    "\n",
    "# 모델의 구조를 다시 확인하여 변경된 부분을 확인\n",
    "summary(model=ConvNeXt_model,\n",
    "        input_size=[32, 3, 224, 224], # 입력 데이터 크기 (batch_size=32, 채널=3, 높이=224, 너비=224)\n",
    "        col_names=['input_size', 'output_size', 'num_params', 'trainable'],  # 출력할 정보 설정\n",
    "        row_settings=['var_names']) # 변수명 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTb6cKqF83it"
   },
   "source": [
    "## 06 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H--aT8R1866W"
   },
   "outputs": [],
   "source": [
    "def update_ema(ema_model: OrderedDict, model: torch.nn.Module, decay: float):\n",
    "    with torch.no_grad():\n",
    "        model_state = model.state_dict()\n",
    "        for name, param in model_state.items():\n",
    "            if param.dtype in (torch.float16, torch.float32, torch.float64):  # EMA 대상\n",
    "                if name in ema_model:\n",
    "                    ema_model[name].mul_(decay).add_(param, alpha=1 - decay)\n",
    "                else:\n",
    "                    ema_model[name] = param.clone()\n",
    "\n",
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    단일 학습 스텝을 수행하는 함수\n",
    "    \"\"\"\n",
    "    model.train()  # 학습 모드 설정\n",
    "    train_loss, train_acc = 0, 0  # 학습 손실 및 정확도 초기화\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)  # 입력 데이터와 라벨을 지정된 장치로 이동\n",
    "        optimizer.zero_grad()  # 이전 단계의 그래디언트 초기화\n",
    "        y_pred = model(X)  # 모델 예측 수행\n",
    "        loss = loss_fn(y_pred, y)  # 손실 계산\n",
    "        loss.backward()  # 역전파(Backpropagation)\n",
    "        optimizer.step()  # 가중치 업데이트\n",
    "\n",
    "        train_loss += loss.item()  # 손실 합산\n",
    "        acc = (y_pred.argmax(dim=1) == y).sum().item() / len(y)  # 정확도 계산\n",
    "        train_acc += acc  # 정확도 합산\n",
    "\n",
    "    return train_loss / len(dataloader), train_acc / len(dataloader)  # 평균 손실 및 정확도 반환\n",
    "\n",
    "\n",
    "def eval_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    단일 평가 스텝을 수행하는 함수\n",
    "    \"\"\"\n",
    "    model.eval()  # 평가 모드 설정\n",
    "    eval_loss, eval_acc = 0, 0  # 평가 손실 및 정확도 초기화\n",
    "\n",
    "    with torch.inference_mode():  # 평가 시 그래디언트 계산 비활성화 (속도 향상)\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)  # 입력 데이터와 라벨을 지정된 장치로 이동\n",
    "            y_pred = model(X)  # 모델 예측 수행\n",
    "            loss = loss_fn(y_pred, y)  # 손실 계산\n",
    "            eval_loss += loss.item()  # 손실 합산\n",
    "            acc = (y_pred.argmax(dim=1) == y).sum().item() / len(y)  # 정확도 계산\n",
    "            eval_acc += acc  # 정확도 합산\n",
    "\n",
    "    return eval_loss / len(dataloader), eval_acc / len(dataloader)  # 평균 손실 및 정확도 반환\n",
    "\n",
    "\n",
    "def train_eval(model: torch.nn.Module,\n",
    "               train_dataloader: torch.utils.data.DataLoader,\n",
    "               val_dataloader: torch.utils.data.DataLoader,\n",
    "               epochs: int,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device) -> List[Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    지정된 에포크(epochs) 동안 모델을 학습하고 평가하는 함수\n",
    "    \"\"\"\n",
    "    results = []  # 학습 및 평가 결과를 저장할 리스트\n",
    "\n",
    "    ema_params = OrderedDict()  # EMA(지수이동평균)를 위한 파라미터 저장용 딕셔너리\n",
    "    ema_decay = 0.9999  # EMA 적용 시 사용될 decay 값 (가중치 평균 비율)\n",
    "\n",
    "    # 전체 학습 시작 시간 기록\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # 학습 단계 수행\n",
    "        train_loss, train_acc = train_step(model, train_dataloader, loss_fn, optimizer, device)\n",
    "        # EMA(지수 이동 평균) 파라미터 업데이트 – 모델 파라미터의 평균을 저장하여 안정적인 평가에 사용\n",
    "        update_ema(ema_params, model, ema_decay)\n",
    "        # 평가 단계 수행\n",
    "        val_loss, val_acc = eval_step(model, val_dataloader, loss_fn, device)\n",
    "\n",
    "        # 현재 학습률 확인\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # 학습 및 평가 결과 출력\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: \\n\"\n",
    "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} \\n\"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | LR: {current_lr:.6f}\")\n",
    "\n",
    "        # 결과 저장\n",
    "        results.append({\n",
    "            \"epoch\": epoch+1,\n",
    "            \"Train_loss\": train_loss,\n",
    "            \"Train_acc\": train_acc,\n",
    "            \"Val_loss\": val_loss,\n",
    "            \"Val_acc\": val_acc,\n",
    "            \"lr\": current_lr\n",
    "        })\n",
    "\n",
    "    # EMA 파라미터 백업 및 적용\n",
    "    original_params = {name: param.data.clone() for name, param in model.named_parameters() if name in ema_params}\n",
    "    for name, param in model.named_parameters():\n",
    "        if name in ema_params:\n",
    "            param.data.copy_(ema_params[name])\n",
    "\n",
    "    ema_val_loss, ema_val_acc = eval_step(model, val_dataloader, loss_fn, device)\n",
    "    print(f\"EMA Validation Accuracy: {ema_val_acc:.4f} | EMA Validation Loss: {ema_val_loss:.4f}\")\n",
    "\n",
    "    # 원래 파라미터 복원\n",
    "    for name, param in model.named_parameters():\n",
    "        if name in original_params:\n",
    "            param.data.copy_(original_params[name])\n",
    "\n",
    "\n",
    "    # 전체 학습 끝 시간 기록\n",
    "    total_end_time = time.time()\n",
    "    print(f\"\\n🕒 전체 학습 시간: {(total_end_time - total_start_time) / 60:.2f}분\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vn_JgivHBHCX"
   },
   "source": [
    "### train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2809475,
     "status": "ok",
     "timestamp": 1743319988641,
     "user": {
      "displayName": "이수인",
      "userId": "16249151905029041959"
     },
     "user_tz": -540
    },
    "id": "4WB-cTuvVyNY",
    "outputId": "6f998ecb-23c3-40b0-8697-a7a429cfe6b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: \n",
      "Train Loss: 1.1046 | Train Acc: 0.7161 \n",
      "Val Loss: 0.4095 | Val Acc: 0.8731 | LR: 0.001000\n",
      "Epoch 2/50: \n",
      "Train Loss: 0.4602 | Train Acc: 0.8586 \n",
      "Val Loss: 0.3043 | Val Acc: 0.8963 | LR: 0.001000\n",
      "Epoch 3/50: \n",
      "Train Loss: 0.3620 | Train Acc: 0.8833 \n",
      "Val Loss: 0.2685 | Val Acc: 0.9062 | LR: 0.001000\n",
      "Epoch 4/50: \n",
      "Train Loss: 0.3048 | Train Acc: 0.9031 \n",
      "Val Loss: 0.2526 | Val Acc: 0.9104 | LR: 0.001000\n",
      "Epoch 5/50: \n",
      "Train Loss: 0.2645 | Train Acc: 0.9133 \n",
      "Val Loss: 0.2432 | Val Acc: 0.9119 | LR: 0.001000\n",
      "Epoch 6/50: \n",
      "Train Loss: 0.2427 | Train Acc: 0.9216 \n",
      "Val Loss: 0.2131 | Val Acc: 0.9204 | LR: 0.001000\n",
      "Epoch 7/50: \n",
      "Train Loss: 0.2206 | Train Acc: 0.9270 \n",
      "Val Loss: 0.1940 | Val Acc: 0.9375 | LR: 0.001000\n",
      "Epoch 8/50: \n",
      "Train Loss: 0.1998 | Train Acc: 0.9335 \n",
      "Val Loss: 0.1982 | Val Acc: 0.9148 | LR: 0.001000\n",
      "Epoch 9/50: \n",
      "Train Loss: 0.1909 | Train Acc: 0.9345 \n",
      "Val Loss: 0.1894 | Val Acc: 0.9303 | LR: 0.001000\n",
      "Epoch 10/50: \n",
      "Train Loss: 0.1856 | Train Acc: 0.9329 \n",
      "Val Loss: 0.2075 | Val Acc: 0.9244 | LR: 0.001000\n",
      "Epoch 11/50: \n",
      "Train Loss: 0.1817 | Train Acc: 0.9342 \n",
      "Val Loss: 0.2006 | Val Acc: 0.9417 | LR: 0.001000\n",
      "Epoch 12/50: \n",
      "Train Loss: 0.1715 | Train Acc: 0.9388 \n",
      "Val Loss: 0.1885 | Val Acc: 0.9416 | LR: 0.001000\n",
      "Epoch 13/50: \n",
      "Train Loss: 0.1573 | Train Acc: 0.9450 \n",
      "Val Loss: 0.1828 | Val Acc: 0.9318 | LR: 0.001000\n",
      "Epoch 14/50: \n",
      "Train Loss: 0.1598 | Train Acc: 0.9437 \n",
      "Val Loss: 0.1890 | Val Acc: 0.9387 | LR: 0.001000\n",
      "Epoch 15/50: \n",
      "Train Loss: 0.1489 | Train Acc: 0.9474 \n",
      "Val Loss: 0.1708 | Val Acc: 0.9445 | LR: 0.001000\n",
      "Epoch 16/50: \n",
      "Train Loss: 0.1442 | Train Acc: 0.9520 \n",
      "Val Loss: 0.1664 | Val Acc: 0.9516 | LR: 0.001000\n",
      "Epoch 17/50: \n",
      "Train Loss: 0.1415 | Train Acc: 0.9515 \n",
      "Val Loss: 0.1606 | Val Acc: 0.9417 | LR: 0.001000\n",
      "Epoch 18/50: \n",
      "Train Loss: 0.1395 | Train Acc: 0.9517 \n",
      "Val Loss: 0.1835 | Val Acc: 0.9402 | LR: 0.001000\n",
      "Epoch 19/50: \n",
      "Train Loss: 0.1457 | Train Acc: 0.9453 \n",
      "Val Loss: 0.1714 | Val Acc: 0.9545 | LR: 0.001000\n",
      "Epoch 20/50: \n",
      "Train Loss: 0.1321 | Train Acc: 0.9536 \n",
      "Val Loss: 0.1607 | Val Acc: 0.9501 | LR: 0.001000\n",
      "Epoch 21/50: \n",
      "Train Loss: 0.1283 | Train Acc: 0.9541 \n",
      "Val Loss: 0.1627 | Val Acc: 0.9601 | LR: 0.001000\n",
      "Epoch 22/50: \n",
      "Train Loss: 0.1257 | Train Acc: 0.9547 \n",
      "Val Loss: 0.1836 | Val Acc: 0.9432 | LR: 0.001000\n",
      "Epoch 23/50: \n",
      "Train Loss: 0.1308 | Train Acc: 0.9514 \n",
      "Val Loss: 0.1824 | Val Acc: 0.9530 | LR: 0.001000\n",
      "Epoch 24/50: \n",
      "Train Loss: 0.1213 | Train Acc: 0.9546 \n",
      "Val Loss: 0.1807 | Val Acc: 0.9430 | LR: 0.001000\n",
      "Epoch 25/50: \n",
      "Train Loss: 0.1308 | Train Acc: 0.9493 \n",
      "Val Loss: 0.1679 | Val Acc: 0.9529 | LR: 0.001000\n",
      "Epoch 26/50: \n",
      "Train Loss: 0.1195 | Train Acc: 0.9567 \n",
      "Val Loss: 0.1581 | Val Acc: 0.9615 | LR: 0.001000\n",
      "Epoch 27/50: \n",
      "Train Loss: 0.1168 | Train Acc: 0.9576 \n",
      "Val Loss: 0.1609 | Val Acc: 0.9530 | LR: 0.001000\n",
      "Epoch 28/50: \n",
      "Train Loss: 0.1162 | Train Acc: 0.9573 \n",
      "Val Loss: 0.1752 | Val Acc: 0.9516 | LR: 0.001000\n",
      "Epoch 29/50: \n",
      "Train Loss: 0.1154 | Train Acc: 0.9586 \n",
      "Val Loss: 0.1657 | Val Acc: 0.9460 | LR: 0.001000\n",
      "Epoch 30/50: \n",
      "Train Loss: 0.1107 | Train Acc: 0.9578 \n",
      "Val Loss: 0.1634 | Val Acc: 0.9488 | LR: 0.001000\n",
      "Epoch 31/50: \n",
      "Train Loss: 0.1091 | Train Acc: 0.9614 \n",
      "Val Loss: 0.1632 | Val Acc: 0.9458 | LR: 0.001000\n",
      "Epoch 32/50: \n",
      "Train Loss: 0.1075 | Train Acc: 0.9578 \n",
      "Val Loss: 0.1921 | Val Acc: 0.9347 | LR: 0.001000\n",
      "Epoch 33/50: \n",
      "Train Loss: 0.1124 | Train Acc: 0.9574 \n",
      "Val Loss: 0.1539 | Val Acc: 0.9587 | LR: 0.001000\n",
      "Epoch 34/50: \n",
      "Train Loss: 0.1062 | Train Acc: 0.9629 \n",
      "Val Loss: 0.1569 | Val Acc: 0.9531 | LR: 0.001000\n",
      "Epoch 35/50: \n",
      "Train Loss: 0.1062 | Train Acc: 0.9598 \n",
      "Val Loss: 0.1747 | Val Acc: 0.9474 | LR: 0.001000\n",
      "Epoch 36/50: \n",
      "Train Loss: 0.1074 | Train Acc: 0.9589 \n",
      "Val Loss: 0.1723 | Val Acc: 0.9544 | LR: 0.001000\n",
      "Epoch 37/50: \n",
      "Train Loss: 0.1055 | Train Acc: 0.9597 \n",
      "Val Loss: 0.1663 | Val Acc: 0.9545 | LR: 0.001000\n",
      "Epoch 38/50: \n",
      "Train Loss: 0.1029 | Train Acc: 0.9638 \n",
      "Val Loss: 0.1824 | Val Acc: 0.9474 | LR: 0.001000\n",
      "Epoch 39/50: \n",
      "Train Loss: 0.1050 | Train Acc: 0.9594 \n",
      "Val Loss: 0.1864 | Val Acc: 0.9543 | LR: 0.001000\n",
      "Epoch 40/50: \n",
      "Train Loss: 0.1035 | Train Acc: 0.9606 \n",
      "Val Loss: 0.1735 | Val Acc: 0.9600 | LR: 0.001000\n",
      "Epoch 41/50: \n",
      "Train Loss: 0.1000 | Train Acc: 0.9624 \n",
      "Val Loss: 0.1845 | Val Acc: 0.9474 | LR: 0.001000\n",
      "Epoch 42/50: \n",
      "Train Loss: 0.0979 | Train Acc: 0.9632 \n",
      "Val Loss: 0.1630 | Val Acc: 0.9559 | LR: 0.001000\n",
      "Epoch 43/50: \n",
      "Train Loss: 0.1059 | Train Acc: 0.9589 \n",
      "Val Loss: 0.1996 | Val Acc: 0.9559 | LR: 0.001000\n",
      "Epoch 44/50: \n",
      "Train Loss: 0.0932 | Train Acc: 0.9649 \n",
      "Val Loss: 0.1582 | Val Acc: 0.9658 | LR: 0.001000\n",
      "Epoch 45/50: \n",
      "Train Loss: 0.0921 | Train Acc: 0.9670 \n",
      "Val Loss: 0.1620 | Val Acc: 0.9687 | LR: 0.001000\n",
      "Epoch 46/50: \n",
      "Train Loss: 0.0954 | Train Acc: 0.9636 \n",
      "Val Loss: 0.1737 | Val Acc: 0.9572 | LR: 0.001000\n",
      "Epoch 47/50: \n",
      "Train Loss: 0.0918 | Train Acc: 0.9627 \n",
      "Val Loss: 0.1775 | Val Acc: 0.9530 | LR: 0.001000\n",
      "Epoch 48/50: \n",
      "Train Loss: 0.0971 | Train Acc: 0.9616 \n",
      "Val Loss: 0.1557 | Val Acc: 0.9574 | LR: 0.001000\n",
      "Epoch 49/50: \n",
      "Train Loss: 0.0967 | Train Acc: 0.9643 \n",
      "Val Loss: 0.1737 | Val Acc: 0.9588 | LR: 0.001000\n",
      "Epoch 50/50: \n",
      "Train Loss: 0.0942 | Train Acc: 0.9675 \n",
      "Val Loss: 0.1791 | Val Acc: 0.9530 | LR: 0.001000\n",
      "EMA Validation Accuracy: 0.8744 | EMA Validation Loss: 0.4029\n",
      "\n",
      "🕒 전체 학습 시간: 46.82분\n"
     ]
    }
   ],
   "source": [
    "# 손실 함수 및 옵티마이저 초기화\n",
    "loss_fn = nn.CrossEntropyLoss()  # 다중 분류 문제에 적합한 크로스 엔트로피 손실 함수 사용\n",
    "optimizer = torch.optim.AdamW(ConvNeXt_model.parameters(), lr=0.001)  # AdamW 옵티마이저 사용, 학습률(lr) 설정\n",
    "\n",
    "# 학습할 총 에포크 수 설정\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "# 학습 실행\n",
    "results = train_eval(model=ConvNeXt_model,\n",
    "                     train_dataloader=train_dataloader,\n",
    "                     val_dataloader=validation_dataloader,\n",
    "                     epochs=NUM_EPOCHS,\n",
    "                     loss_fn=loss_fn,\n",
    "                     optimizer=optimizer,\n",
    "                     device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nizwunc-T_he"
   },
   "source": [
    "## 07 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGNESaqNKDgv"
   },
   "outputs": [],
   "source": [
    "# 결과를 데이터프레임으로 변환\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F1_84555J13C"
   },
   "outputs": [],
   "source": [
    "# 테스트 셋 평가\n",
    "test_loss, test_acc = eval_step(model=ConvNeXt_model,\n",
    "                                dataloader=test_dataloader,\n",
    "                                loss_fn=loss_fn,\n",
    "                                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1743320005443,
     "user": {
      "displayName": "이수인",
      "userId": "16249151905029041959"
     },
     "user_tz": -540
    },
    "id": "cbyA64udJ3JD",
    "outputId": "7a366fe3-e660-419d-f3d3-4a8f6b30beef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.966146\n",
      "Test Loss: 0.147261\n"
     ]
    }
   ],
   "source": [
    "# 결과\n",
    "print(f\"Test accuracy: {test_acc:.6f}\")\n",
    "print(f\"Test Loss: {test_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-7Cj8cS7XkU"
   },
   "source": [
    "## 08 DB 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5105,
     "status": "ok",
     "timestamp": 1743320010550,
     "user": {
      "displayName": "이수인",
      "userId": "16249151905029041959"
     },
     "user_tz": -540
    },
    "id": "qqYNjhSO7aEv",
    "outputId": "9456b302-94b5-41df-c8ca-21a49d47d68a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# DB 연결 정보 입력 (Aiven MySQL 기준)\n",
    "host = 'YOUR_AIVEN_HOST'\n",
    "port = 'YOUR_AIVEN_PORT'\n",
    "username = 'YOUR_USERNAME'\n",
    "password = 'YOUR_PASSWORD'\n",
    "database = 'YOUR_DATABASE'\n",
    "\n",
    "# SQLAlchemy 엔진 생성\n",
    "engine = create_engine(f\"mysql+pymysql://{username}:{password}@{host}:{port}/{database}\")\n",
    "# DataFrame을 MySQL에 저장\n",
    "results_df.to_sql(name='train_logs_convnextnet', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# 테스트 결과를 DataFrame으로 변환\n",
    "test_result_df = pd.DataFrame([{\n",
    "    \"model_name\": \"ConvNeXt\",\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_acc\": test_acc\n",
    "}])\n",
    "\n",
    "test_result_df.to_sql(name='test_results', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkzlX8FEBOMQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMH/tjwGDFZ0I8Z+rw1hWQz",
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "1y45MMfWg46lSc-ksTmRQTLv9EXgEgYaz",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
